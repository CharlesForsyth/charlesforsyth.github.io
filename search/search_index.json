{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Charles Forsyth Linux/HPC System Administrator for the University of California, Riverside","title":"Home"},{"location":"#charles-forsyth","text":"Linux/HPC System Administrator for the University of California, Riverside","title":"Charles Forsyth"},{"location":"cv/","text":"Charles Forsyth Lead HPC System Administrator with experience in architecting, installing, administering and supporting large scale HPC Infrastructures for RD&E operations and Academic Institutions. 20+ years of Linux System Administration. (Larg Linux Clusters, Thousands of Cores, Lustre, SAN and NAS Storage, Network Licensing and Software support) Experience Linux/HPC System Administrator University of California, Riverside Jun 2017 - Present Architect, install, administer and support campus HPC Systems. Enable researchers and students by providing training classes and seminars. XSEDE Campus Champion, consulting and enabling researchers and students on how to access NSF backed supercomputing centers and national laboratories. UCR Representative for the University of California Research IT Committee; serving to align Research IT and HPC goals across all nine UC Campuses and the UC Office of the President. Designed and administering functional on-demand HPC Clusters in AWS. Linux/HPC System Administrator Corning Incorporated Jan 2012 - Jun 2017 5 yrs 6 mos Direct experience administering the following: Provisioning and configuration management (ILo, cobbler, iPXE, Kickstarts) Monitoring and alerting (Nagios, ELK stack) Storage systems (HP MSA SAN, Lustre, Isilon NAS) Networking (Infiniband, 10GB and 1GB Ethernet, 16GB FC) VM infrastructure (VMWare, Citrix XenServer, Ovirt KVM) Operating systems (CentOS Linux 4->7, Windows XP->Server 2012R2) Programing/Scripting (c++,c#, Python,Bash,Powershell) Remote desktop software (VNC, RDP, X11,NiceDCV) Source control (GIT) Databases (MySQL,MS SQL) Server software (SSH, Cgroups, Apache and all other major applications) Cloud services (OpenStack, AWS) Project management (Lead both internal and external projects.) Hardware service contracts (400+ Server, Storage and Networking support contracts) Server room power and cooling systems (150kVA+ APC UPS, large LieBert AC units) Cluster software (All major Scientific Modeling package (e.g. Ansys, Comsol, Abaqus)) Cluster software (Parallel Libraries such as Intel MPI and OpenMPI) Cluster software (Mathematical libraries such as MKL and FFTW) License management (FlexLM, RLM, LMX,MathLM supporting 60+ network licensed software packages) Customer training and documentation development Education Kaplan University Bachelor of Science (BS), Information Technology 2013-2015 3.89 Iota Sigma Tau Honor Society Golden Key International Honor Society Alpha Beta Kappa National Honor Society Ridley-Lowell Business & Technical Institute Networking and Technical Support Specialist 2010-2011 4.0 The program provides necessary training to support end users and computer operations in business environments with skills such as computer and peripherals maintenance, networking, computer operating systems, computer hardware, and software applications. Qualified certification equal to CompTia A+ , Microsoft Certified Systems Engineer (MCSE), Networking +, Security +, and Linux + Dean's List, 4.0 Average , Top GPA of class United States Navy Advanced Electronics Technology/Technician 1994-1997 AC Circuits Basic Electronics Laboratory DC Circuits Digital Microprocessor Fundamentals Electronic Communications Electronic Systems Troubleshooting Radio/Radar Fundamentals Solid State Electronics Analog Circuits Communications Circuit Analysis Digital Circuit Logic","title":"CV"},{"location":"cv/#charles-forsyth","text":"Lead HPC System Administrator with experience in architecting, installing, administering and supporting large scale HPC Infrastructures for RD&E operations and Academic Institutions. 20+ years of Linux System Administration. (Larg Linux Clusters, Thousands of Cores, Lustre, SAN and NAS Storage, Network Licensing and Software support)","title":"Charles Forsyth"},{"location":"cv/#experience","text":"","title":"Experience"},{"location":"cv/#linuxhpc-system-administrator","text":"","title":"Linux/HPC System Administrator"},{"location":"cv/#university-of-california-riverside","text":"Jun 2017 - Present Architect, install, administer and support campus HPC Systems. Enable researchers and students by providing training classes and seminars. XSEDE Campus Champion, consulting and enabling researchers and students on how to access NSF backed supercomputing centers and national laboratories. UCR Representative for the University of California Research IT Committee; serving to align Research IT and HPC goals across all nine UC Campuses and the UC Office of the President. Designed and administering functional on-demand HPC Clusters in AWS.","title":"University of California, Riverside"},{"location":"cv/#linuxhpc-system-administrator_1","text":"","title":"Linux/HPC System Administrator"},{"location":"cv/#corning-incorporated","text":"Jan 2012 - Jun 2017 5 yrs 6 mos Direct experience administering the following: Provisioning and configuration management (ILo, cobbler, iPXE, Kickstarts) Monitoring and alerting (Nagios, ELK stack) Storage systems (HP MSA SAN, Lustre, Isilon NAS) Networking (Infiniband, 10GB and 1GB Ethernet, 16GB FC) VM infrastructure (VMWare, Citrix XenServer, Ovirt KVM) Operating systems (CentOS Linux 4->7, Windows XP->Server 2012R2) Programing/Scripting (c++,c#, Python,Bash,Powershell) Remote desktop software (VNC, RDP, X11,NiceDCV) Source control (GIT) Databases (MySQL,MS SQL) Server software (SSH, Cgroups, Apache and all other major applications) Cloud services (OpenStack, AWS) Project management (Lead both internal and external projects.) Hardware service contracts (400+ Server, Storage and Networking support contracts) Server room power and cooling systems (150kVA+ APC UPS, large LieBert AC units) Cluster software (All major Scientific Modeling package (e.g. Ansys, Comsol, Abaqus)) Cluster software (Parallel Libraries such as Intel MPI and OpenMPI) Cluster software (Mathematical libraries such as MKL and FFTW) License management (FlexLM, RLM, LMX,MathLM supporting 60+ network licensed software packages) Customer training and documentation development","title":"Corning Incorporated"},{"location":"cv/#education","text":"","title":"Education"},{"location":"cv/#kaplan-university","text":"","title":"Kaplan University"},{"location":"cv/#bachelor-of-science-bs-information-technology-2013-2015-389","text":"Iota Sigma Tau Honor Society Golden Key International Honor Society Alpha Beta Kappa National Honor Society","title":"Bachelor of Science (BS), Information Technology 2013-2015   3.89"},{"location":"cv/#ridley-lowell-business-technical-institute","text":"","title":"Ridley-Lowell Business &amp; Technical Institute"},{"location":"cv/#networking-and-technical-support-specialist-2010-2011-40","text":"The program provides necessary training to support end users and computer operations in business environments with skills such as computer and peripherals maintenance, networking, computer operating systems, computer hardware, and software applications. Qualified certification equal to CompTia A+ , Microsoft Certified Systems Engineer (MCSE), Networking +, Security +, and Linux + Dean's List, 4.0 Average , Top GPA of class","title":"Networking and Technical Support Specialist  2010-2011   4.0"},{"location":"cv/#united-states-navy","text":"","title":"United States Navy"},{"location":"cv/#advanced-electronics-technologytechnician-1994-1997","text":"AC Circuits Basic Electronics Laboratory DC Circuits Digital Microprocessor Fundamentals Electronic Communications Electronic Systems Troubleshooting Radio/Radar Fundamentals Solid State Electronics Analog Circuits Communications Circuit Analysis Digital Circuit Logic","title":"Advanced Electronics Technology/Technician   1994-1997"},{"location":"hpc-architecture/","text":"","title":"Architecture"},{"location":"hpc-aws/","text":"Cloud HPC AWS High Performance Computing in the Cloud with AWS. This is work I have done at the High Performance Compiting Center at the University of Calforina, Riverside. Introduction Getting started using HPCC and Amazon Web Service (AWS) to quickly create an on-demand cluster private to you. AWS Cluster benefits. Build a private cluster in 10 min. Any number of nodes, auto scaling (up and down), limit 20 to start Any type of compute nodes High memory High CPU single/multi node GPUs For only as long as you need it - delete when done Familiar interface and job scheduler Build as many of these clusters as you need (even at the same time) Pay for only the time you use it - per/min billing Example Cast This is an simple example of a full HPC workflow using AWS. Presentation on HPCC AWS Cluster","title":"HPC in the Cloud"},{"location":"hpc-aws/#cloud-hpc","text":"","title":"Cloud HPC"},{"location":"hpc-aws/#aws","text":"High Performance Computing in the Cloud with AWS. This is work I have done at the High Performance Compiting Center at the University of Calforina, Riverside.","title":"AWS"},{"location":"hpc-aws/#introduction","text":"Getting started using HPCC and Amazon Web Service (AWS) to quickly create an on-demand cluster private to you.","title":"Introduction"},{"location":"hpc-aws/#aws-cluster-benefits","text":"Build a private cluster in 10 min. Any number of nodes, auto scaling (up and down), limit 20 to start Any type of compute nodes High memory High CPU single/multi node GPUs For only as long as you need it - delete when done Familiar interface and job scheduler Build as many of these clusters as you need (even at the same time) Pay for only the time you use it - per/min billing","title":"AWS Cluster benefits."},{"location":"hpc-aws/#example-cast","text":"This is an simple example of a full HPC workflow using AWS.","title":"Example Cast"},{"location":"hpc-aws/#presentation-on-hpcc-aws-cluster","text":"","title":"Presentation on HPCC AWS Cluster"},{"location":"hpc-code/","text":"Code Bash Python R C / C++ / c# Fortran Perl Ruby Batch (windows) Power Shell (windows) Bash Bash is mainly found in Linux and is the default shell in most versions. It can be used in windows through the use of: cygwin Containers Windows Subsystem for Linux SHEBANG The shebang #! followed by the path /bin/bash -l to the interpreter that will be use to execute the script. This needs to be first line of the script. #!/bin/bash -l You can also use a more portable version of this with /usr/bin/env bash -l . /usr/bin/env is a application used to run the first bash found in your PATH . #!/usr/bin/env bash -l Python R C / C++ / C Open MP atomic.c #include <stdio.h> #include <omp.h> int main(void) { int count = 0; int id; #pragma omp parallel shared(count) { #pragma omp atomic count++; id = omp_get_thread_num(); printf(\"Count is %d on thread %d\\n\",count,id); } printf(\"Number of threads: %d\\n\",count); } simple-parallel.c int main(int argc, char *argv[]) { const int N = 10; int i, a[N], myid; #pragma omp parallel for for (i = 0; i < N; i++){ a[i] = 2 * i; myid = omp_get_thread_num(); printf(\"my thread %d , i is %d and a[i] is %d \\n\",myid,i, a[i]); } return 0; } hola.c To Complie: mpic++ -fopenmp hola.c #include <stdio.h> #include <omp.h> int main (int argc, char *argv[ ]) { int id, nthreads; #pragma omp parallel private(id) { id = omp_get_thread_num(); printf(\"hola from %d\\n\", id); #pragma omp barrier if ( id == 0 ) { nthreads = omp_get_num_threads(); printf(\"%d threads said hola!\\n\",nthreads); } } return 0; } loops.c #include <stdio.h> #include <omp.h> #define N 100 int main(void) { float a[N], b[N], c[N]; int i, id; omp_set_dynamic(0); // ensures use of all available threads omp_set_num_threads(20); // sets number of all available threads to 20 /* Initialize arrays a and b. */ for (i = 0; i < N; i++) { a[i] = i * 1.0; b[i] = i * 2.0; } /* Compute values of array c in parallel. */ #pragma omp parallel shared(a, b, c) private(i) { #pragma omp for for (i = 0; i < N; i++) c[i] = a[i] + b[i]; id = omp_get_thread_num(); printf (\"Thread %d working\\n\", id); } printf (\"%f\\n\", c[10]); } hybrid_hello.c #define _GNU_SOURCE #include <stdio.h> #include <unistd.h> #include <string.h> #include <sched.h> #include <mpi.h> #include <omp.h> /* to compile mpicc -openmp -o hybrid_hello.x hybrid_hello.c */ static char *cpuset_to_cstr(cpu_set_t *mask, char *str) { char *ptr = str; int i, j, entry_made = 0; for (i = 0; i < CPU_SETSIZE; i++) { if (CPU_ISSET(i, mask)) { int run = 0; entry_made = 1; for (j = i + 1; j < CPU_SETSIZE; j++) { if (CPU_ISSET(j, mask)) run++; else break; } if (!run) sprintf(ptr, \"%d,\", i); else if (run == 1) { sprintf(ptr, \"%d,%d,\", i, i + 1); i++; } else { sprintf(ptr, \"%d-%d,\", i, i + run); i += run; } while (*ptr != 0) ptr++; } } ptr -= entry_made; *ptr = 0; return(str); } int main(int argc, char *argv[]) { int rank, thread; cpu_set_t coremask; char clbuf[7 * CPU_SETSIZE], hnbuf[64]; MPI_Init(&argc, &argv); MPI_Comm_rank(MPI_COMM_WORLD, &rank); memset(clbuf, 0, sizeof(clbuf)); memset(hnbuf, 0, sizeof(hnbuf)); (void)gethostname(hnbuf, sizeof(hnbuf)); #pragma omp parallel private(thread, coremask, clbuf) { thread = omp_get_thread_num(); (void)sched_getaffinity(0, sizeof(coremask), &coremask); cpuset_to_cstr(&coremask, clbuf); #pragma omp barrier /*printf(\"Hello from rank %d, thread %d, on %s. (core affinity = %s)\\n\", * rank, thread, hnbuf, clbuf);*/ printf(\"Hello from node %s, core %s; AKA rank %d, thread %d\\n\", hnbuf, clbuf, rank, thread); } MPI_Finalize(); return(0); } hellompi.c mpicc hellompi.c -I/opt/linux/centos/7.x/x86_64/pkgs/openmpi/2.0.1-slurm-16.05.4/include -pthread -o hellompi #include <stdio.h> #include <mpi.h> #include <unistd.h> int main (argc, argv) int argc; char *argv[]; { int rank, size; char hostname[1024]; MPI_Init (&argc, &argv); /* starts MPI */ MPI_Comm_rank (MPI_COMM_WORLD, &rank); /* get current process id */ MPI_Comm_size (MPI_COMM_WORLD, &size); /* get number of processes */ gethostname(hostname, 1024); printf( \"Hello world from process %d of %d on Node %s\\n\", rank, size, hostname ); MPI_Finalize(); return 0; } Fortran workshare.f90 program worksharef90 use omp_lib integer:: a(1:10),b(1:10),c(1:10) integer:: n,i n=10 !$OMP PARALLEL SHARED(n,a,b,c) !$OMP WORKSHARE b(1:n)=b(1:n)+1 c(1:n)=c(1:n)+2 a(1:n)=b(1:n)+c(1:n) !$OMP END WORKSHARE !$OMP END PARALLEL do i =1, n write(6,*)i, a(i) enddo end reduction.f90 PROGRAM REDUCTION IMPLICIT NONE INTEGER nthread, OMP_GET_THREAD_NUM INTEGER I,J,K I=0 J=0 K=0 PRINT *, \"Before parallel section: I=\",I,\" J=\", J,\" K=\",K PRINT *, \"\" !$OMP PARALLEL DEFAULT(PRIVATE) REDUCTION(+:I)& !$OMP REDUCTION(*:J) REDUCTION(MAX:K) nthread=OMP_GET_THREAD_NUM() I = nthread J = nthread K = nthread PRINT *, \"Thread \",nthread,\" I=\",I,\" J=\", J,\" K=\",K !$OMP END PARALLEL PRINT *, \"\" Print *, \"Reduction Operators used + * MAX\" PRINT *, \"After parallel section: I=\",I,\" J=\", J,\" K=\",K END PROGRAM REDUCTION Fortran Perl Ruby Batch (windows) Power Shell (windows)","title":"Code"},{"location":"hpc-code/#code","text":"Bash Python R C / C++ / c# Fortran Perl Ruby Batch (windows) Power Shell (windows)","title":"Code"},{"location":"hpc-code/#bash","text":"Bash is mainly found in Linux and is the default shell in most versions. It can be used in windows through the use of: cygwin Containers Windows Subsystem for Linux","title":"Bash"},{"location":"hpc-code/#shebang","text":"The shebang #! followed by the path /bin/bash -l to the interpreter that will be use to execute the script. This needs to be first line of the script. #!/bin/bash -l You can also use a more portable version of this with /usr/bin/env bash -l . /usr/bin/env is a application used to run the first bash found in your PATH . #!/usr/bin/env bash -l","title":"SHEBANG"},{"location":"hpc-code/#python","text":"","title":"Python"},{"location":"hpc-code/#r","text":"","title":"R"},{"location":"hpc-code/#c-c-c","text":"","title":"C / C++ / C"},{"location":"hpc-code/#open-mp","text":"","title":"Open MP"},{"location":"hpc-code/#atomicc","text":"#include <stdio.h> #include <omp.h> int main(void) { int count = 0; int id; #pragma omp parallel shared(count) { #pragma omp atomic count++; id = omp_get_thread_num(); printf(\"Count is %d on thread %d\\n\",count,id); } printf(\"Number of threads: %d\\n\",count); }","title":"atomic.c"},{"location":"hpc-code/#simple-parallelc","text":"int main(int argc, char *argv[]) { const int N = 10; int i, a[N], myid; #pragma omp parallel for for (i = 0; i < N; i++){ a[i] = 2 * i; myid = omp_get_thread_num(); printf(\"my thread %d , i is %d and a[i] is %d \\n\",myid,i, a[i]); } return 0; }","title":"simple-parallel.c"},{"location":"hpc-code/#holac","text":"To Complie: mpic++ -fopenmp hola.c #include <stdio.h> #include <omp.h> int main (int argc, char *argv[ ]) { int id, nthreads; #pragma omp parallel private(id) { id = omp_get_thread_num(); printf(\"hola from %d\\n\", id); #pragma omp barrier if ( id == 0 ) { nthreads = omp_get_num_threads(); printf(\"%d threads said hola!\\n\",nthreads); } } return 0; }","title":"hola.c"},{"location":"hpc-code/#loopsc","text":"#include <stdio.h> #include <omp.h> #define N 100 int main(void) { float a[N], b[N], c[N]; int i, id; omp_set_dynamic(0); // ensures use of all available threads omp_set_num_threads(20); // sets number of all available threads to 20 /* Initialize arrays a and b. */ for (i = 0; i < N; i++) { a[i] = i * 1.0; b[i] = i * 2.0; } /* Compute values of array c in parallel. */ #pragma omp parallel shared(a, b, c) private(i) { #pragma omp for for (i = 0; i < N; i++) c[i] = a[i] + b[i]; id = omp_get_thread_num(); printf (\"Thread %d working\\n\", id); } printf (\"%f\\n\", c[10]); } hybrid_hello.c #define _GNU_SOURCE #include <stdio.h> #include <unistd.h> #include <string.h> #include <sched.h> #include <mpi.h> #include <omp.h> /* to compile mpicc -openmp -o hybrid_hello.x hybrid_hello.c */ static char *cpuset_to_cstr(cpu_set_t *mask, char *str) { char *ptr = str; int i, j, entry_made = 0; for (i = 0; i < CPU_SETSIZE; i++) { if (CPU_ISSET(i, mask)) { int run = 0; entry_made = 1; for (j = i + 1; j < CPU_SETSIZE; j++) { if (CPU_ISSET(j, mask)) run++; else break; } if (!run) sprintf(ptr, \"%d,\", i); else if (run == 1) { sprintf(ptr, \"%d,%d,\", i, i + 1); i++; } else { sprintf(ptr, \"%d-%d,\", i, i + run); i += run; } while (*ptr != 0) ptr++; } } ptr -= entry_made; *ptr = 0; return(str); } int main(int argc, char *argv[]) { int rank, thread; cpu_set_t coremask; char clbuf[7 * CPU_SETSIZE], hnbuf[64]; MPI_Init(&argc, &argv); MPI_Comm_rank(MPI_COMM_WORLD, &rank); memset(clbuf, 0, sizeof(clbuf)); memset(hnbuf, 0, sizeof(hnbuf)); (void)gethostname(hnbuf, sizeof(hnbuf)); #pragma omp parallel private(thread, coremask, clbuf) { thread = omp_get_thread_num(); (void)sched_getaffinity(0, sizeof(coremask), &coremask); cpuset_to_cstr(&coremask, clbuf); #pragma omp barrier /*printf(\"Hello from rank %d, thread %d, on %s. (core affinity = %s)\\n\", * rank, thread, hnbuf, clbuf);*/ printf(\"Hello from node %s, core %s; AKA rank %d, thread %d\\n\", hnbuf, clbuf, rank, thread); } MPI_Finalize(); return(0); } hellompi.c mpicc hellompi.c -I/opt/linux/centos/7.x/x86_64/pkgs/openmpi/2.0.1-slurm-16.05.4/include -pthread -o hellompi #include <stdio.h> #include <mpi.h> #include <unistd.h> int main (argc, argv) int argc; char *argv[]; { int rank, size; char hostname[1024]; MPI_Init (&argc, &argv); /* starts MPI */ MPI_Comm_rank (MPI_COMM_WORLD, &rank); /* get current process id */ MPI_Comm_size (MPI_COMM_WORLD, &size); /* get number of processes */ gethostname(hostname, 1024); printf( \"Hello world from process %d of %d on Node %s\\n\", rank, size, hostname ); MPI_Finalize(); return 0; }","title":"loops.c"},{"location":"hpc-code/#fortran","text":"","title":"Fortran"},{"location":"hpc-code/#worksharef90","text":"program worksharef90 use omp_lib integer:: a(1:10),b(1:10),c(1:10) integer:: n,i n=10 !$OMP PARALLEL SHARED(n,a,b,c) !$OMP WORKSHARE b(1:n)=b(1:n)+1 c(1:n)=c(1:n)+2 a(1:n)=b(1:n)+c(1:n) !$OMP END WORKSHARE !$OMP END PARALLEL do i =1, n write(6,*)i, a(i) enddo end","title":"workshare.f90"},{"location":"hpc-code/#reductionf90","text":"PROGRAM REDUCTION IMPLICIT NONE INTEGER nthread, OMP_GET_THREAD_NUM INTEGER I,J,K I=0 J=0 K=0 PRINT *, \"Before parallel section: I=\",I,\" J=\", J,\" K=\",K PRINT *, \"\" !$OMP PARALLEL DEFAULT(PRIVATE) REDUCTION(+:I)& !$OMP REDUCTION(*:J) REDUCTION(MAX:K) nthread=OMP_GET_THREAD_NUM() I = nthread J = nthread K = nthread PRINT *, \"Thread \",nthread,\" I=\",I,\" J=\", J,\" K=\",K !$OMP END PARALLEL PRINT *, \"\" Print *, \"Reduction Operators used + * MAX\" PRINT *, \"After parallel section: I=\",I,\" J=\", J,\" K=\",K END PROGRAM REDUCTION","title":"reduction.f90"},{"location":"hpc-code/#fortran_1","text":"","title":"Fortran"},{"location":"hpc-code/#perl","text":"","title":"Perl"},{"location":"hpc-code/#ruby","text":"","title":"Ruby"},{"location":"hpc-code/#batch-windows","text":"","title":"Batch (windows)"},{"location":"hpc-code/#power-shell-windows","text":"","title":"Power Shell (windows)"},{"location":"hpc-hardware/","text":"HPC Hardware Switches Cables Storage Nodes Power Cooling Switches Ethernet Infiniband QDR FDR EDR Director Switch Satellite Switches FiberChannel HBAs 16G Cables Ethernet Copper CAT 5/6 Fiber Single Multi-Mode Infiniband QDR FDR EDR Copper Fiber FiberChannel Fiber SAS Direct Connect SAS Power Node to Wall Node to Rack Rack to PDU PDU to UPS Storage Disks HDD Size and Speed SSD Size, Speed and Useable number of Writes Disk Shelves Controllers ARI Systems These are storage shelves sold by RAID Inc. in which are rebranded I'm sure. I have used HP MSA 2000's and they seems to be the same thing right down to the web interface. The command line is the same also. Show Versions ssh to the controller manage is the default username ssh manage@<controller ip or hostname> # show versions Controller A Versions --------------------- Bundle Version: GL222R061 Build Date: Tue May 29 14:57:00 MDT 2018 Controller B Versions --------------------- Bundle Version: GL222R061 Build Date: Tue May 29 14:57:00 MDT 2018 Success: Command completed successfully. (2018-11-29 22:50:53) Upgrade Firmware on ARI System backing GPFS - Download firmware from RAID ftp site ftp://files.raidinc.com/u-california-riverside/fromRAID GL222R061-RaidInc.bin GL222R061-RaidInc.md5 - Shutdown IO to cluster - Unmount all file systems to all nodes # mmumount all -a # mmlsmount all -a - Shutdown GPFS on all nodes # mmshutdown -a # mmgetstate -a -Get ARI logs before upgrade FTP to storage controller to get logs from # ftp manage@<storge controller IP> password !manage # get logs <name of file>.zip - Upgrade firmware on controllers from CLI SSH to one of the controller IP addresses: ssh <ip address of controller A or B> Username: manage Password: !manage Run the following command to enable partner firmware upgrade: NOTE: This will allow the firmware to automatically both controllers. using FTP. To exit the telnet session type exit. # set advanced-settings partner-firmware-upgrade enabled # exit Run the following command to flash the firmware to controller A or B: ftp <ip address of controller A or B> Username: manage Password: !manage # put <firmware file.bin> flash NOTE: Once the firmware is finished flashing on a controller, the controller will automatically reboot. NOTE: When the first controller is down rebooting the 2nc controller will automatically upgrade and reboot Please wait for both controller to flash and reboot. Verify new firmware is loaded on both controllers # show versions Controller A Versions --------------------- Bundle Version: GL222R061-xx Build Date: xxxxxxxxxxxxxxxxxxx Controller B Versions --------------------- Bundle Version: GL222R061-xx Build Date: xxxxxxxxxxxxxxxxxxx - Get ARI logs after upgrade FTP to storage controller to get logs from # ftp manage@<storge controller IP> password !manage # get logs <name of file>.zip - Rebalance vdisks on controllers from CLI Telnet to one of the controller IP addresses: telnet <ip address of controller A or B> Username: manage Password: !manage # show vdisks # set vdisk owner b vdisk10 to move the controller owner for vdisk10 # show vdisks - Restart GPFS # mmstartup -a # mmgetstate -a - Remount GPFS # mmmount all -a # mmlsmount all -a - Restart IO to cluster JBODS Curretly Supporting ARI JBODS attached to the ARI Storage controller. Connected with 2 x 12G SAS cables. Tape Cold Storage Nodes Hypervisor CPU High Core Count MEM High Memory Graphical GPU SR-IOV to provide 3D graphics to each VM NVIDIA GRID K2 NICs 1g Cat 6 Management Interface 10g Fiber Ethernet SR-IOV would be awesome here also For public interface Mellonox Connect X 3 or higher Infiniband NIC SR-IOV to provide IB to each VM FDR Fiber Channel HBA SAN connection to shared storage Compute CPU Balance between core count and CPU Speed Intel Currently buying: lscpu shows bash Vendor ID: GenuineIntel CPU family: 6 Model: 79 Model name: Intel(R) Xeon(R) CPU E5-2683 v4 @ 2.10GHz Stepping: 1 CPU MHz: 2599.980 CPU max MHz: 3000.0000 CPU min MHz: 1200.0000 BogoMIPS: 4190.19 Virtualization: VT-x L1d cache: 32K L1i cache: 32K L2 cache: 256K L3 cache: 40960K NUMA node0 CPU(s): 0-15,32-47 NUMA node1 CPU(s): 16-31,48-63 Flags: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe syscall nx pdpe1gb rdtscp lm constant_tsc arch_perfmon pebs bts rep_good nopl xtopology nonstop_tsc aperfmperf eagerfpu pni pclmulqdq dtes64 monitor ds_cpl vmx smx est tm2 ssse3 fma cx16 xtpr pdcm pcid dca sse4_1 sse4_2 x2apic movbe popcnt tsc_deadline_timer aes xsave avx f16c rdrand lahf_lm abm 3dnowprefetch epb cat_l3 cdp_l3 invpcid_single intel_pt spec_ctrl ibpb_support tpr_shadow vnmi flexpriority ept vpid fsgsbase tsc_adjust bmi1 hle avx2 smep bmi2 erms invpcid rtm cqm rdt_a rdseed adx smap xsaveopt cqm_llc cqm_occup_llc cqm_mbm_total cqm_mbm_local dtherm ida arat pln pts ARM Really watching this. 28-core Cavium ThunderX2 processors running at 2.0 GHz These are powering a new supercomputer at Sandia National Lab. And another This is becoming more and more main stream. AMD Still keeping up. I manage a few hundered nodes of AMD but we are phasing these out MEM The more the better Check memory on the node cat /proc/meminfo | head -3 bash i22:~# cat /proc/meminfo | head -3 MemTotal: 528079828 kB MemFree: 495977976 kB MemAvailable: 502751960 kB free -g ```bash i22:~# free -g total used free shared buff/cache available Mem: 503 31 461 1 10 467 Swap: 3 0 3 ``` smem smem reports physical memory usage, taking shared memory pages into account. Unshared memory is reported as the USS (Unique Set Size). Shared memory is divided evenly among the processes sharing that memory. The unshared memory (USS) plus a process's proportion of shared memory is reported as the PSS (Proportional Set Size). The USS and PSS only include physical memory usage. They do not include memory that has been swapped out to disk. Memory can be reported by process, by user, by mapping, or system wide. Both text mode and graphical output are available. Example smem -w bash i22:~# smem -w Area Used Cache Noncache firmware/hardware 0 0 0 kernel image 0 0 0 kernel dynamic memory 14962228 7805104 7157124 userspace memory 17016380 1589884 15426496 free memory 496101220 496101220 0 other examples 128G Min. 256G Ok 512G Good 1TB Great Speed: 1600 MHz dmidecode --type memory | grep Speed | grep -v Unknown | uniq GPU SSD NIC Storage Special Power Rack Power Server Room Power Cooling Server Room HVAC Libert CRAC units","title":"Hardware"},{"location":"hpc-hardware/#hpc-hardware","text":"Switches Cables Storage Nodes Power Cooling","title":"HPC Hardware"},{"location":"hpc-hardware/#switches","text":"Ethernet Infiniband QDR FDR EDR Director Switch Satellite Switches FiberChannel HBAs 16G","title":"Switches"},{"location":"hpc-hardware/#cables","text":"Ethernet Copper CAT 5/6 Fiber Single Multi-Mode Infiniband QDR FDR EDR Copper Fiber FiberChannel Fiber SAS Direct Connect SAS Power Node to Wall Node to Rack Rack to PDU PDU to UPS","title":"Cables"},{"location":"hpc-hardware/#storage","text":"Disks HDD Size and Speed SSD Size, Speed and Useable number of Writes","title":"Storage"},{"location":"hpc-hardware/#disk-shelves","text":"","title":"Disk Shelves"},{"location":"hpc-hardware/#controllers","text":"","title":"Controllers"},{"location":"hpc-hardware/#ari-systems","text":"These are storage shelves sold by RAID Inc. in which are rebranded I'm sure. I have used HP MSA 2000's and they seems to be the same thing right down to the web interface. The command line is the same also.","title":"ARI Systems"},{"location":"hpc-hardware/#show-versions","text":"ssh to the controller manage is the default username ssh manage@<controller ip or hostname> # show versions Controller A Versions --------------------- Bundle Version: GL222R061 Build Date: Tue May 29 14:57:00 MDT 2018 Controller B Versions --------------------- Bundle Version: GL222R061 Build Date: Tue May 29 14:57:00 MDT 2018 Success: Command completed successfully. (2018-11-29 22:50:53)","title":"Show Versions"},{"location":"hpc-hardware/#upgrade-firmware-on-ari-system-backing-gpfs","text":"- Download firmware from RAID ftp site ftp://files.raidinc.com/u-california-riverside/fromRAID GL222R061-RaidInc.bin GL222R061-RaidInc.md5 - Shutdown IO to cluster - Unmount all file systems to all nodes # mmumount all -a # mmlsmount all -a - Shutdown GPFS on all nodes # mmshutdown -a # mmgetstate -a -Get ARI logs before upgrade FTP to storage controller to get logs from # ftp manage@<storge controller IP> password !manage # get logs <name of file>.zip - Upgrade firmware on controllers from CLI SSH to one of the controller IP addresses: ssh <ip address of controller A or B> Username: manage Password: !manage Run the following command to enable partner firmware upgrade: NOTE: This will allow the firmware to automatically both controllers. using FTP. To exit the telnet session type exit. # set advanced-settings partner-firmware-upgrade enabled # exit Run the following command to flash the firmware to controller A or B: ftp <ip address of controller A or B> Username: manage Password: !manage # put <firmware file.bin> flash NOTE: Once the firmware is finished flashing on a controller, the controller will automatically reboot. NOTE: When the first controller is down rebooting the 2nc controller will automatically upgrade and reboot Please wait for both controller to flash and reboot. Verify new firmware is loaded on both controllers # show versions Controller A Versions --------------------- Bundle Version: GL222R061-xx Build Date: xxxxxxxxxxxxxxxxxxx Controller B Versions --------------------- Bundle Version: GL222R061-xx Build Date: xxxxxxxxxxxxxxxxxxx - Get ARI logs after upgrade FTP to storage controller to get logs from # ftp manage@<storge controller IP> password !manage # get logs <name of file>.zip - Rebalance vdisks on controllers from CLI Telnet to one of the controller IP addresses: telnet <ip address of controller A or B> Username: manage Password: !manage # show vdisks # set vdisk owner b vdisk10 to move the controller owner for vdisk10 # show vdisks - Restart GPFS # mmstartup -a # mmgetstate -a - Remount GPFS # mmmount all -a # mmlsmount all -a - Restart IO to cluster","title":"Upgrade Firmware on ARI System backing GPFS"},{"location":"hpc-hardware/#jbods","text":"Curretly Supporting ARI JBODS attached to the ARI Storage controller. Connected with 2 x 12G SAS cables. Tape Cold Storage","title":"JBODS"},{"location":"hpc-hardware/#nodes","text":"Hypervisor CPU High Core Count MEM High Memory Graphical GPU SR-IOV to provide 3D graphics to each VM NVIDIA GRID K2 NICs 1g Cat 6 Management Interface 10g Fiber Ethernet SR-IOV would be awesome here also For public interface Mellonox Connect X 3 or higher Infiniband NIC SR-IOV to provide IB to each VM FDR Fiber Channel HBA SAN connection to shared storage Compute CPU Balance between core count and CPU Speed Intel Currently buying: lscpu shows bash Vendor ID: GenuineIntel CPU family: 6 Model: 79 Model name: Intel(R) Xeon(R) CPU E5-2683 v4 @ 2.10GHz Stepping: 1 CPU MHz: 2599.980 CPU max MHz: 3000.0000 CPU min MHz: 1200.0000 BogoMIPS: 4190.19 Virtualization: VT-x L1d cache: 32K L1i cache: 32K L2 cache: 256K L3 cache: 40960K NUMA node0 CPU(s): 0-15,32-47 NUMA node1 CPU(s): 16-31,48-63 Flags: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe syscall nx pdpe1gb rdtscp lm constant_tsc arch_perfmon pebs bts rep_good nopl xtopology nonstop_tsc aperfmperf eagerfpu pni pclmulqdq dtes64 monitor ds_cpl vmx smx est tm2 ssse3 fma cx16 xtpr pdcm pcid dca sse4_1 sse4_2 x2apic movbe popcnt tsc_deadline_timer aes xsave avx f16c rdrand lahf_lm abm 3dnowprefetch epb cat_l3 cdp_l3 invpcid_single intel_pt spec_ctrl ibpb_support tpr_shadow vnmi flexpriority ept vpid fsgsbase tsc_adjust bmi1 hle avx2 smep bmi2 erms invpcid rtm cqm rdt_a rdseed adx smap xsaveopt cqm_llc cqm_occup_llc cqm_mbm_total cqm_mbm_local dtherm ida arat pln pts ARM Really watching this. 28-core Cavium ThunderX2 processors running at 2.0 GHz These are powering a new supercomputer at Sandia National Lab. And another This is becoming more and more main stream. AMD Still keeping up. I manage a few hundered nodes of AMD but we are phasing these out MEM The more the better Check memory on the node cat /proc/meminfo | head -3 bash i22:~# cat /proc/meminfo | head -3 MemTotal: 528079828 kB MemFree: 495977976 kB MemAvailable: 502751960 kB free -g ```bash i22:~# free -g total used free shared buff/cache available Mem: 503 31 461 1 10 467 Swap: 3 0 3 ``` smem smem reports physical memory usage, taking shared memory pages into account. Unshared memory is reported as the USS (Unique Set Size). Shared memory is divided evenly among the processes sharing that memory. The unshared memory (USS) plus a process's proportion of shared memory is reported as the PSS (Proportional Set Size). The USS and PSS only include physical memory usage. They do not include memory that has been swapped out to disk. Memory can be reported by process, by user, by mapping, or system wide. Both text mode and graphical output are available. Example smem -w bash i22:~# smem -w Area Used Cache Noncache firmware/hardware 0 0 0 kernel image 0 0 0 kernel dynamic memory 14962228 7805104 7157124 userspace memory 17016380 1589884 15426496 free memory 496101220 496101220 0 other examples 128G Min. 256G Ok 512G Good 1TB Great Speed: 1600 MHz dmidecode --type memory | grep Speed | grep -v Unknown | uniq GPU SSD NIC Storage Special","title":"Nodes"},{"location":"hpc-hardware/#power","text":"Rack Power Server Room Power","title":"Power"},{"location":"hpc-hardware/#cooling","text":"Server Room HVAC Libert CRAC units","title":"Cooling"},{"location":"hpc-home/","text":"High-Performance Computing Currently I have this broken down into the following sections: Hardware Provisioning Architecture Schedulers Software Scripts HPC in the Cloud Monitoring Metrics","title":"Intro"},{"location":"hpc-home/#high-performance-computing","text":"Currently I have this broken down into the following sections: Hardware Provisioning Architecture Schedulers Software Scripts HPC in the Cloud Monitoring Metrics","title":"High-Performance Computing"},{"location":"hpc-linux/","text":"Introduction *Much of this page was copied directly from the HPCC Linux manual page. Linux used as the operating system for most super computers. GNU/Linux Distributions Ubuntu - A beginner-friendly Linux OS based on Debian. A good choice for most people. OpenSuSE - An alternative to Ubuntu for new users. Debian - A general-purpose Linux OS with a large software package repository and support community. Red Hat Enterprise Linux (RHEL) - A general-purpose Linux OS supported by Red Hat, Inc. Requires purchase. CentOS - A community-supported version of RHEL that's free to download and use. The UCR HPCC cluster runs on CentOS 7. Fedora - A developer-oriented Linux OS sponsored by Red Hat. Arch Linux - A highly-customizable Linux OS for power users. Family tree of the GNU/Linux distributions Basics Command-Line Syntax for this Manual Remember the UNIX/Linux command line is case sensitive! All commands in this manual are printed in gray code boxes. The hash (pound) sign \"#\" indicates end of a command and the start of a comment. The notation <...> refers to variables and file names that need to be specified by the user. The symbols < and > need to be excluded. Orientation Viewing and changing the present working directory: pwd # \"Print working directory\"; show your current path ls # \"List\" contents of current directory ls -l # Similar to ls, but provides additional info on files and directories ls -a # List all files, including hidden files (.name) as well ls -R # Lists subdirectories recursively ls -t # Lists files in chronological order cd <dir_name> # \"Change directory\" to specified path cd # Brings you back to your home directory cd .. # Moves one directory up cd ../../ # Moves two directories up (and so on) cd - # Go back to you were previously (before the last directory change) The tilde symbol (~) gets interpreted as the path to your home directory when by itself or at the beginning of a word: echo ~ # View the full (complete) path of your home find ~ # List all your files (including everything in sub-directories) ls ~ # List the top level files of your home directory du -sch ~/* # Calculate the \"disk usage\" of files in your home Viewing file info, user, and host: stat <file-name> # Show last modification time stamps, permissions, and size of a file whoami # Shows your user name (same as \"echo $USER\") hostname # Shows on which machine you are (same as \"echo $HOSTNAME\") Files and directories mkdir <dir_name> # Creates specified directory rmdir <dir_name> # Removes empty directory rm <file_name> # Removes file_name rm -r <dir_name> # Removes directory including its contents, but asks for confirmation rm -rf <dir_name> # Same as above, but turns confirmation off. Use with caution cp <name> <path> # Copy file/directory as specified in path (-r to include content in directories) mv <name1> <name2> # Renames directories or files mv <name> <path> # Moves file/directory as specified in path Copy and paste The methods differ depending where you are. In a command line environment: Cut last word with keyboard only Ctrl+w Press multiple times to cut more than one word Paste with keyboard only Ctrl+y In a non-command line desktop environment (e.g. Firefox): Copy Ctrl+c Paste Ctrl+v Command line <-> desktop exchange: Copy text out of the command line and into the desktop: Shift+Ctrl+c or Apple+c Paste text from the desktop into the command line: Shift+Ctrl+v or Apple+v On any Linux desktop! Copy with mouse only Simply select the text with the mouse Paste with mouse only Click the middle mouse button or both left/right buttons simultaneously Handy shortcuts At the command prompt: up(down)_key - scrolls through command history history shows all commands you have used recently Auto Completion: TAB - completes program_path/file_name Taking control over the cursor (the pointer on the command line): Ctrl+a # Cursor to beginning of command line Ctrl+e # Cursor to end of command line Ctrl+w # Cut last word Ctrl+k # Cut to the end of the line Ctrl+y # Paste (\"yank\") content that was cut earlier (by Ctrl-w or Ctrl-k) When specifying file names: . (dot) - refers to the present working directory ~ (tilde) or ~/ - refers to user's home directory Other Useful Unix Commands df # disk space free -g # memory info in Megabytes uname -a # shows tech info about machine bc # command-line calculator (to exit type 'quit') wget ftp://ftp.ncbi.nih.... # file download from web /sbin/ifconfig # give IP and other network info ln -s <original_filename> <new_filename> # creates symbolic link to file or directory du -sh # displays disk space usage of current directory du -sh * # displays disk space usage of individual files/directories du -s * | sort -nr # shows disk space used by different directories/files sorted by size Unix Help help <command> # Show help for a Bash command man <something> # Show the manual page for a program (press the 'q' key to exit) man wc # Manual on program 'word count' wc wc --help # Short help on wc soap -h # For less standard programs Online help: Google is your friend. Universally available Linux commands, with detailed examples and explanations: https://www.linuxconfig.org/linux-commands Finding files, directories and applications find -name \"*pattern*\" # Searches for *pattern* in and below current directory find /usr/local -name \"*blast*\" # Finds file names *blast* in specfied directory find /usr/local -iname \"*blast*\" # Same as above, but case insensitive Additional useful arguments: -user , -group , -ctime find ~ -type f -mtime -2 # Finds all files you have modified in the last two days locate <pattern> # Finds files and dirs that are written into update file which <application_name> # Location of application whereis <application_name> # Searches for executables in set of directories yum list installed | grep <mypattern> # Find CentOS packages and refine search with grep pattern Finding things in files grep <pattern> <file> # Provides lines in 'file' where pattern 'appears' # If pattern is shell function use single-quotes: '>' grep -H <pattern> # -H prints out file name in front of pattern grep 'pattern' <file> | wc # pipes lines with pattern into word count wc (see chapter 8) # wc arguments: -c: show only bytes, -w: show only words, # -l: show only lines; help on regular expressions: # $ man 7 regex or man perlre find /home/my_dir -name '*.txt' | xargs grep -c ^.* # Counts line numbers on many # files and records each count along with individual file # name; find and xargs are used to circumvent the Linux # wildcard limit to apply this function on thousands of files. Ownership Overview In Linux (and Unix systems in general), access to files and directories is controlled by a system of owners, groups, and permission bits. Changing these settings is necessary to control access by other users. The permission system also affects what files can be executed. Ownership Levels user (u) - User ownership of a file/directory. This user has the special right to change the permission bits and group ownership. group (g) - Group ownership of a file/directory. Members of this group may be assigned greater access rights than non-members. other (o) - Everyone else that isn't the owning user or from the owning group. Permission Bits The elemental permissions in Linux/Unix are read, write, and execute. Users and groups can have one many, or none of these rights. Their meanings are as follows: Letter Number File Directory Read r 4 View the contents View the listings Write w 2 Modify the contents Create a new file, or rename or delete existing files Execute x 1 Execute a program/script Traversal rights Checking Permissions Annotated output for ls -la : ---------- File type (d = directory, - = regular file, l = symlink) |--------- User permission triplet || ------ Group permission triplet || | --- Other permission triplet || | | || | | [user] [group] drwx-----x 61 aleong operations 4096 Feb 24 16:39 ./ drwxr-xr-x 688 root root 262144 Feb 24 11:05 ../ drwx------ 2 aleong operations 4096 Feb 2 22:45 .ssh/ drwxr-xr-x 5 aleong operations 4096 Dec 12 15:57 Downloads/ drwxr-xr-x 2 aleong operations 4096 Jan 9 16:29 bin/ -rw------- 1 aleong operations 7960 Feb 23 18:37 .bash_history -rw-r--r-- 1 aleong operations 306 Nov 3 15:08 .bashrc -rw-r--r-- 1 aleong operations 677 Apr 8 2013 .profile -rw-r--r-- 1 aleong operations 128 Nov 30 12:38 .tmux.conf -rw-r--r-- 1 aleong operations 12126 Nov 2 13:14 .vimrc lrwxrwxrwx 1 aleong operations 23 Sep 12 10:49 bigdata -> /bigdata/operations/aleong/ -rw-r--r-- 1 aleong operations 5657 Sep 19 11:31 bookmarks.html lrwxrwxrwx 1 aleong operations 23 Sep 12 10:49 shared -> /bigdata/operations/shared/ Assign write and execute permissions to user and group chmod ug+rx my_file To remove all permissions from all three user groups chmod ugo-rwx my_file # '+' causes the permissions selected to be added # '-' causes them to be removed # '=' causes them to be the only permissions that the file has. chmod +rx public_html/ or $ chmod 755 public_html/ # Example for number system: Change ownership chown <user> <file or dir> # changes user ownership chgrp <group> <file or dir> # changes group ownership chown <user>:<group> <file or dir> # changes user & group ownership Process Management top # view top consumers of memory and CPU (press 1 to see per-CPU statistics) who # Shows who is logged into system w # Shows which users are logged into system and what they are doing ps # Shows processes running by user ps -e # Shows all processes on system; try also '-a' and '-x' arguments ps aux | grep <user_name> # Shows all processes of one user ps ax --tree # Shows the child-parent hierarchy of all processes ps -o %t -p <pid> # Shows how long a particular process was running. # (E.g. 6-04:30:50 means 6 days 4 hours ...) Ctrl z <enter> # Suspend (put to sleep) a process fg # Resume (wake up) a suspended process and brings it into foreground bg # Resume (wake up) a suspended process but keeps it running # in the background. Ctrl c # Kills the process that is currently running in the foreground kill <process-ID> # Kills a specific process kill -9 <process-ID> # NOTICE: \"kill -9\" is a very violent approach. # It does not give the process any time to perform cleanup procedures. kill -l # List all of the signals that can be sent to a proccess kill -s SIGSTOP <process-ID> # Suspend (put to sleep) a specific process kill -s SIGCONT <process-ID> # Resume (wake up) a specific process nice -n <nice_value> <cmd> # Run a program with lower priority. Be nice to other headnode users. # Higher \"nice\" values mean lower priority. Range 0-20 renice -n <priority_value> <process-ID> # Changes the priority of an existing process. More on Terminating Processes DigitalOcean - How To Use ps, kill, and nice to Manage Processes in Linux Vim Manual Basics vim <my_file_name> # open/create file with vim Once you are in Vim the most important commands are i , : and ESC . The i key brings you into the insert mode for typing. ESC brings you out of there. And the : key starts the command mode at the bottom of the screen. In the following text, all commands starting with : need to be typed in the command mode. All other commands are typed in the normal mode after hitting the ESC key. Modifier Keys to Control Vim i # INSERT MODE ESC # NORMAL (NON-EDITING) MODE : # commands start with ':' :w # save command; if you are in editing mode you have to hit ESC first!! :q # quit file, don't save :q! # exits WITHOUT saving any changes you have made :wq # save and quit R # replace MODE r # replace only one character under cursor q: # history of commands (from NORMAL MODE!), to reexecute one of them, select and hit enter! :w new_filename # saves into new file :#,#w new_filename # saves specific lines (#,#) to new file :# # go to specified line number Vim Help Online Help Find help on the web. Google will find answers to most questions on vi and vim (try searching for both terms). Purdue University Vi Tutorial Animated Vim Tutorial: https://linuxconfig.org/vim-tutorial Useful list of vim commands: Vim Commands Cheat Sheet VimCard Help from Command Line vimtutor # open vim tutorial from shell Help in Vim :help # opens help within vim, hit :q to get back to your file :help <topic> # opens help on specified topic :help_topic| CTRL-] # when you are in help this command opens help topic specified between |...|, # CTRL-t brings you back to last topic :help <topic> CTRL-D # gives list of help topics that contain key word : <up-down keys> # like in shell you get recent commands!!!! Moving Around in Files $ # moves cursor to end of line A # same as $, but switches to insert mode 0 (zero) # moves cursor to beginning of line CTRL-g # shows at status line filename and the line you are on SHIFT-G # brings you to bottom of file, type line number (isn't displayed) then SHIFT-G # brings you to specified line# Line Wrapping and Line Numbers :set nowrap # no word wrapping, :set wrap # back to wrapping :set number # shows line numbers, :set nonumber # back to no-number mode Working with Many Files & Splitting Windows vim -o *.txt # opens many files at once and displays them with horizontal # split, '-O' does vertical split vim *.txt # opens many files at once; ':n' switches between files :wall or :qall # write or quit all open files :args *.txt # places all the relevant files in the argument list :all # splits all files in the argument list (buffer) horizontally CTRL-w # switch between windows :split # shows same file in two windows :split <file-to-open> # opens second file in new window :vsplit # splits windows vertically, very useful for tables, \":set scrollbind\" let's you scroll all open windows simultaneously :close # closes current window :only # closes all windows except current one Spell Checking & Dictionary :set spell # turns on spell checking :set nospell # turns spell checking off :! dict <word> # meaning of word :! wn 'word' -over # synonyms of word Enabling Syntax Highlighting :set filetype=perl # Turns on syntax coloring for a chosen programming language. :set syntax on # Turns syntax highlighting on :set syntax off # Turns syntax highlighting off Undo and Redo u # undo last command U # undo all changes on current line CTRL-R # redo one change which was undone Deleting Things x # deletes what is under cursor dw # deletes from curser to end of word including the space de # deletes from curser to end of word NOT including the space cw # deletes rest of word and lets you then insert, hit ESC to continue with NORMAL mode c$ # deletes rest of line and lets you then insert, hit ESC to continue with with NORMAL mode d$ # deletes from cursor to the end of the line dd # deletes entire line 2dd # deletes next two lines, continues: 3dd, 4dd and so on. Copy & Paste yy # copies line, for copying several lines do 2yy, 3yy and so on p # pastes clipboard behind cursor Search in Files /my_pattern # searches for my_pattern downwards, type n for next match ?my_pattern # seraches for my_pattern upwards, type n for next match :set ic # switches to ignore case search (case insensitive) :set hls # switches to highlight search (highlights search hits) Replacements with Regular Expression Support Great intro: A Tao of Regular Expressions :s/old_pat/new_pat/ # replaces first occurrence in a line :s/old_pat/new_pat/g # replaces all occurrence in a line :s/old_pat/new_pat/gc # add 'c' to ask for confirmation :#,#s/old_pat/new_pat/g # replaces all occurrence between line numbers: #,# :%s/old_pat/new_pat/g # replaces all occurrence in file :%s/\\(pattern1\\)\\(pattern2\\)/\\1test\\2/g # regular expression to insert, you need here '\\' in front of parentheses (<# Perl) :%s/\\(pattern.*\\)/\\1 my_tag/g # appends something to line containing pattern (<# .+ from Perl is .* in VIM) :%s/\\(pattern\\)\\(.*\\)/\\1/g # removes everything in lines after pattern :%s/\\(At\\dg\\d\\d\\d\\d\\d\\.\\d\\)\\(.*\\)/\\1\\t\\2/g # inserts tabs between At1g12345.1 and Description :%s/\\n/new_pattern/g # replaces return signs :%s/pattern/\\r/g # replace pattern with return signs!! :%s/\\(\\n\\)/\\1\\1/g # insert additional return signs :%s/\\(^At\\dg\\d\\d\\d\\d\\d.\\d\\t.\\{-}\\t.\\{-}\\t.\\{-}\\t.\\{-}\\t\\).\\{-}\\t/\\1/g # replaces content between 5th and 6th tab (5th column), '{-}' turns off 'greedy' behavior :#,#s/\\( \\{-} \\|\\.\\|\\n\\)/\\1/g # performs simple word count in specified range of text :%s/\\(E\\{6,\\}\\)/<font color=\"green\">\\1<\\/font>/g # highlight pattern in html colors, here highlighting of >= 6 occurences of Es :%s/\\([A-Z]\\)/\\l\\1/g # change uppercase to lowercase, '%s/\\([A-Z]\\)/\\u\\1/g' does the opposite :g/my_pattern/ s/\\([A-Z]\\)/\\l\\1/g | copy $ # uses 'global' command to apply replace function only on those lines that match a certain pattern. The 'copy $' command after the pipe '|' prints all matching lines at the end of the file. :args *.txt | all | argdo %s/\\old_pat/new_pat/ge | update # command 'args' places all relevant files in the argument list (buffer); 'all' displays each file in separate split window; command 'argdo' applies replacement to all files in argument list (buffer); flag 'e' is necessary to avoid stop at error messages for files with no matches; command 'update' saves all changes to files that were updated. Useful Utilities in Vim Matching Parentheses Place cursor on (, [ or { and type % # cursor moves to matching parentheses Printing and Inserting Files :ha # prints entire file :#,#ha # prints specified lines: #,# :r <filename> # inserts content of specified file after cursor Convert Text File to HTML Format :runtime! syntax/2html.vim # run this command with open file in Vim Shell Commands in Vim :!<SHELL_COMMAND> <ENTER> # executes any shell command, hit <enter> to return :sh # switches window to shell, 'exit' switches back to vim Using Vim as Table Editor v starts visual mode for selecting characters V starts visual mode for selecting lines` CTRL-V starts visual mode for selecting blocks (use CTRL-q in gVim under Windows). This allows column-wise selections and operations like inserting and deleting columns. To restrict substitute commands to a column, one can select it and switch to the command-line by typing : . After this the substitution syntax for a selected block looks like this: '<,'>s///. :set scrollbind starts simultaneous scrolling of 'vsplitted' files. To set to horizontal binding of files, use command :set scrollopt=hor (after first one). Run all these commands before the :split command. :AlignCtrl I= \\t then :%Align This allows to align tables by column separators (here '\\t') when the Align utility from Charles Campbell's is installed. To sort table rows by selected lines or block, perform the visual select and then hit F3 key. The rest is interactive. To enable this function, one has to include in the .vimrc file the Vim sort script from Gerald Lai. Modify Vim Settings The default settings in Vim are controlled by the .vimrc file in your home directory. see last chapter of vimtutor (start from shell) useful .vimrc sample when vim starts to respond very slowly then one may need to delete the .viminf* files in home directory Text Viewing more <my_file> # views text, use space bar to browse, hit 'q' to exit less <my_file> # a more versatile text viewer than 'more', 'q' exits, 'G' moves to end of text, # 'g' to beginning, '/' find forward, '?' find backwards cat <my_file> # concatenates files and prints content to standard output Text Editors Vi and Vim Non-graphical (terminal-based) editor. Vi is guaranteed to be available on any system. Vim is the improved version of vi. Emacs Non-graphical or window-based editor. You still need to know keystroke commands to use it. Installed on all Linux distributions and on most other Unix systems. XEmacs More sophisticated version of emacs, but usually not installed by default. All common commands are available from menus. Very powerful editor, with built-in syntax checking, Web-browsing, news-reading, manual-page browsing, etc. Pico Simple terminal-based editor available on most versions of Unix. Uses keystroke commands, but they are listed in logical fashion at bottom of screen. Nano A simple terminal-based editor which is default on modern Debian systems. The Unix Shell When you log into UNIX/LINUX system, then is starts a program called the Shell. It provides you with a working environment and interface to the operating system. Usually there are several different shell programs installed. The shell program bash is one of the most common ones. finger <user_name> # shows which shell you are using chsh -l # gives list of shell programs available on your system (does not work on all UNIX variants) <shell_name> # switches to different shell STDIN, STDOUT, STDERR, Redirections, and Wildcards See LINUX HOWTOs By default, UNIX commands read from standard input (STDIN) and send their output to standard out (STDOUT). You can redirect them by using the following commands: <beginning-of-filename>* # * is wildcard to specify many files ls > file # prints ls output into specified file command < my_file # uses file after '<' as STDIN command >> my_file # appends output of one command to file command | tee my_file # writes STDOUT to file and prints it to screen command > my_file; cat my_file # writes STDOUT to file and prints it to screen command > /dev/null # turns off progress info of applications by redirecting # their output to /dev/null grep my_pattern my_file | wc # Pipes (|) output of 'grep' into 'wc' grep my_pattern my_non_existing_file 2 > my_stderr # prints STDERR to file Useful shell commands cat <file1> <file2> > <cat.out> # concatenate files in output file 'cat.out' paste <file1> <file2> > <paste.out> # merges lines of files and separates them by tabs (useful for tables) cmp <file1> <file2> # tells you whether two files are identical diff <fileA> <fileB> # finds differences between two files head -<number> <file> # prints first lines of a file tail -<number> <file> # prints last lines of a file split -l <number> <file> # splits lines of file into many smaller ones csplit -f out fasta_batch \"%^>%\" \"/^>/\" \"{*}\" # splits fasta batch file into many files # at '>' sort <file> # sorts single file, many files and can merge (-m) # them, -b ignores leading white space, ... sort -k 2,2 -k 3,3n input_file > output_file # sorts in table column 2 alphabetically and # column 3 numerically, '-k' for column, '-n' for # numeric sort input_file | uniq > output_file # uniq command removes duplicates and creates file/table # with unique lines/fields join -1 1 -2 1 <table1> <table2> # joins two tables based on specified column numbers # (-1 file1, 1: col1; -2: file2, col2). It assumes # that join fields are sorted. If that is not the case, # use the next command: sort table1 > table1a; sort table2 > table2a; join -a 1 -t \"$(echo -e '\\t')\" table1a table2a > table3 # '-a <table>' prints all lines of specified table! # Default prints only all lines the two tables have in # common. '-t \"$(echo -e '\\t')\" ->' forces join to # use tabs as field separator in its output. Default is # space(s)!!! cat my_table | cut -d , -f1-3 # cut command prints only specified sections of a table, # -d specifies here comma as column separator (tab is # default), -f specifies column numbers. grep # see chapter 4 egrep # see chapter 4 Screen Screen references Screen Turorial Screen Cheat Sheet Starting a New Screen Session screen # Start a new session screen -S <some-name> # Start a new session and gives it a name Commands to Control Screen Ctrl-a d # Detach from the screen session Ctrl-a c # Create a new window inside the screen session Ctrl-a Space # Switch to the next window Ctrl-a a # Switch to the window that you were previously on Ctrl-a \" # List all open windows. Double-quotes \" are typed with the Shift key Ctrl-d or type exit # Exit out of the current window. Exiting form the last window will end the screen session Ctrl-a [ # Enters the scrolling mode. Use Page Up and Page Down keys to scroll through the window. Hit the Enter key twice to return to normal mode. Attaching to Screen Sessions From any computer, you can attach to a screen session after SSH-ing into a server. screen -r # Attaches to an existing session, if there is only one screen -r # Lists available sessions and their names, if there are more then one session running screen -r <some-name> # Attaches to a specific session screen -r <first-few-letters-of-name> # Type just the first few letters of the name # and you will be attached to the session you need Destroying Screen Sessions Terminate all programs that are running in the screen session. The standard way to do that is: Ctrl-c Exit out of your shell: exit Repeat steps 1 and 2 until you see the message: [screen is terminating] There may be programs running in different windows of the same screen session. That's why you may need to terminate programs and exit shells multiple time. Tabs and a Reasonably Large History Buffer For a better experience with screen, run cp ~/.screenrc ~/.screenrc.backup 2> /dev/null echo 'startup_message off defscrollback 10240 caption always \"%{=b dy}{ %{= dm}%H %{=b dy}}%={ %?%{= dc}%-Lw%?%{+b dy}(%{-b r}%n:%t%{+b dy})%?(%u)%?%{-dc}%?%{= dc}%+Lw%? %{=b dy}}\" ' > ~/.screenrc Simple One-Liner Shell Scripts Web page for script download . Renames many files .old to .new. To test things first, replace 'do mv' with 'do echo mv': for i in *.input; do mv $i ${i/\\.old/\\.new}; done for i in *\\ *; do mv \"$i\" \"${i// /_}\"; done # Replaces spaces in files by underscores Run an application in loops on many input files: for i in *.input; do ./application $i; done Run fastacmd from BLAST program in loops on many .input files and create corresponding .out files: for i in *.input; do fastacmd -d /data/../database_name -i $i > $i.out; done Run SAM's target99 on many input files: for i in *.pep; do target99 -db /usr/../database_name -seed $i -out $i; done Search in many files for a pattern and print occurrences together with file names. for j in 0 1 2 3 4 5 6 7 8 9; do grep -iH <my_pattern> *$j.seq; done Example of how to run an interactive application (tmpred) that asks for file name input/output: for i in *.pep; do echo -e \"$i\\n\\n17\\n33\\n\\n\\n\" | ./tmpred $i > $i.out; done Run BLAST2 for all .fasa1/ .fasta2 file pairs in the order specified by file names and write results into one file: for i in *.fasta1; do blast2 -p blastp -i $i -j ${i/_*fasta1/_*fasta2} >> my_out_file; done This example uses two variables in a for loop. The content of the second variable gets specified in each loop by a replace function. Runs BLAST2 in all-against-all mode and writes results into one file ('-F F' turns low-complexity filter off): for i in *.fasta; do for j in *.fasta; do blast2 -p blastp -F F -i $i -j $j >> my_out_file; done; done; Simple One-Liner Perl Scripts Small collection of useful one-liners: perl -p -i -w -e 's/pattern1/pattern2/g' my_input_file # Replaces a pattern in a file by a another pattern using regular expressions. # $1 or \\1: back-references to pattern placed in parentheses # -p: lets perl know to write program # -i.bak: creates backup file *.bak, only -i doesn't # -w: turns on warnings # -e: executable code follows Parse lines based on patterns: perl -ne 'print if (/my_pattern1/ ? ($c=1) : (--$c > 0)); print if (/my_pattern2/ ? ($d = 1) : (--$d > 0))' my_infile > my_outfile # Parses lines that contain pattern1 and pattern2. # The following lines after the pattern can be specified in '$c=1' and '$d=1'. # For logical OR use this syntax: '/(pattern1|pattern2)/'. SSH SSH is the main protocal used to communicate with or establish a terminal on remote systems. Example ssh <username>@<remote-address> If you want to use a specific ssh key for this connection use the -i flag. ssh -i ~/.ssh/mykey <username>@<remote-address> If your username on the remote system is the same as your local username then you can omit the username from the command. Passwordless login. You can use ssh (RSA) keys to login with out the need for a password. (this is much quicker and very useful) Generate your ssh keys ssh-keygen Enter a blank password when asked in order to have a passwordless key By default the key will be stored as .ssh/id_rsa You can change this path to which ever you like Copy the public key to the remote system (there is now a tool for this) ssh-copy-id <username>@<remote-system> You can pass the -i flag to this command to copy a specific public key. This places your public key into the the file .ssh/authorized_keys on the remote system. You can do this manually if you like. Once this is complete you can login without a password. SSH remote commands Often you may want to just run a command on the remote system. Just put the command or muplitple commands surounded by quotes after the ssh command ssh <username>@<remote-host> <command-you-want-to-run> ssh <username>@<remote-host> \"<command-you-want-to-run>; <command-you-want-to-run>; <command-you-want-to-run>\" Remote Copy: wget, scp, ncftp Wget Use wget to download a file from the web: wget ftp://ftp.ncbi.nih.... # file download from www; add option '-r' to download entire directories SCP Use scp to copy files between machines (ie. laptop to server): scp source target # Use form 'userid@machine_name' if your local and remote user ids are different. # If they are the same you can use only 'machine_name'. Here are more scp examples: scp user@remote_host:file.name . # Copies file from server to local machine (type from local # machine prompt). The '.' copies to pwd, you can specify # here any directory, use wildcards to copy many files. scp file.name user@remote_host:~/dir/newfile.name # Copies file from local machine to server. scp -r user@remote_host:directory/ ~/dir # Copies entire directory from server to local machine. Nice FTP From the linux command line run ncftp and use it to get files: ncftp ncftp> open ftp.ncbi.nih.gov ncftp> cd /blast/executables ncftp> get blast.linux.tar.Z (skip extension: @) ncftp> bye Archiving and Compressing Creating Archives tar -cvf my_file.tar mydir/ # Builds tar archive of files or directories. For directories, execute command in parent directory. Don't use absolute path. tar -czvf my_file.tgz mydir/ # Builds tar archive with compression of files or directories. For # directories, execute command in parent directory. Don't use absolute path. zip -r mydir.zip mydir/ # Command to archive a directory (here mydir) with zip. tar -jcvf mydir.tar.bz2 mydir/ # Creates *.tar.bz2 archive Viewing Archives tar -tvf my_file.tar tar -tzvf my_file.tgz Extracting Archives tar -xvf my_file.tar tar -xzvf my_file.tgz gunzip my_file.tar.gz # or unzip my_file.zip, uncompress my_file.Z, # or bunzip2 for file.tar.bz2 find -name '*.zip' | xargs -n 1 unzip # this command usually works for unzipping # many files that were compressed under Windows tar -jxvf mydir.tar.bz2 # Extracts *.tar.bz2 archive Try also: tar zxf blast.linux.tar.Z tar xvzf file.tgz Important options: f: use archive file p: preserve permissions v: list files processed x: exclude files listed in FILE z: filter the archive through gzip Environment Variables xhost user@host # adds X permissions for user on server. echo $DISPLAY # shows current display settings export DISPLAY=<local_IP>:0 # change environment variable unsetenv DISPLAY # removes display variable env # prints all environment variables List of directories that the shell will search when you type a command: echo $PATH You can edit your default DISPLAY setting for your account by adding it to file .bash_profile","title":"Linux Basics"},{"location":"hpc-linux/#introduction","text":"*Much of this page was copied directly from the HPCC Linux manual page. Linux used as the operating system for most super computers.","title":"Introduction"},{"location":"hpc-linux/#gnulinux-distributions","text":"Ubuntu - A beginner-friendly Linux OS based on Debian. A good choice for most people. OpenSuSE - An alternative to Ubuntu for new users. Debian - A general-purpose Linux OS with a large software package repository and support community. Red Hat Enterprise Linux (RHEL) - A general-purpose Linux OS supported by Red Hat, Inc. Requires purchase. CentOS - A community-supported version of RHEL that's free to download and use. The UCR HPCC cluster runs on CentOS 7. Fedora - A developer-oriented Linux OS sponsored by Red Hat. Arch Linux - A highly-customizable Linux OS for power users. Family tree of the GNU/Linux distributions","title":"GNU/Linux Distributions"},{"location":"hpc-linux/#basics","text":"","title":"Basics"},{"location":"hpc-linux/#command-line-syntax-for-this-manual","text":"Remember the UNIX/Linux command line is case sensitive! All commands in this manual are printed in gray code boxes. The hash (pound) sign \"#\" indicates end of a command and the start of a comment. The notation <...> refers to variables and file names that need to be specified by the user. The symbols < and > need to be excluded.","title":"Command-Line Syntax for this Manual"},{"location":"hpc-linux/#orientation","text":"Viewing and changing the present working directory: pwd # \"Print working directory\"; show your current path ls # \"List\" contents of current directory ls -l # Similar to ls, but provides additional info on files and directories ls -a # List all files, including hidden files (.name) as well ls -R # Lists subdirectories recursively ls -t # Lists files in chronological order cd <dir_name> # \"Change directory\" to specified path cd # Brings you back to your home directory cd .. # Moves one directory up cd ../../ # Moves two directories up (and so on) cd - # Go back to you were previously (before the last directory change) The tilde symbol (~) gets interpreted as the path to your home directory when by itself or at the beginning of a word: echo ~ # View the full (complete) path of your home find ~ # List all your files (including everything in sub-directories) ls ~ # List the top level files of your home directory du -sch ~/* # Calculate the \"disk usage\" of files in your home Viewing file info, user, and host: stat <file-name> # Show last modification time stamps, permissions, and size of a file whoami # Shows your user name (same as \"echo $USER\") hostname # Shows on which machine you are (same as \"echo $HOSTNAME\")","title":"Orientation"},{"location":"hpc-linux/#files-and-directories","text":"mkdir <dir_name> # Creates specified directory rmdir <dir_name> # Removes empty directory rm <file_name> # Removes file_name rm -r <dir_name> # Removes directory including its contents, but asks for confirmation rm -rf <dir_name> # Same as above, but turns confirmation off. Use with caution cp <name> <path> # Copy file/directory as specified in path (-r to include content in directories) mv <name1> <name2> # Renames directories or files mv <name> <path> # Moves file/directory as specified in path","title":"Files and directories"},{"location":"hpc-linux/#copy-and-paste","text":"The methods differ depending where you are. In a command line environment: Cut last word with keyboard only Ctrl+w Press multiple times to cut more than one word Paste with keyboard only Ctrl+y In a non-command line desktop environment (e.g. Firefox): Copy Ctrl+c Paste Ctrl+v Command line <-> desktop exchange: Copy text out of the command line and into the desktop: Shift+Ctrl+c or Apple+c Paste text from the desktop into the command line: Shift+Ctrl+v or Apple+v On any Linux desktop! Copy with mouse only Simply select the text with the mouse Paste with mouse only Click the middle mouse button or both left/right buttons simultaneously","title":"Copy and paste"},{"location":"hpc-linux/#handy-shortcuts","text":"At the command prompt: up(down)_key - scrolls through command history history shows all commands you have used recently Auto Completion: TAB - completes program_path/file_name Taking control over the cursor (the pointer on the command line): Ctrl+a # Cursor to beginning of command line Ctrl+e # Cursor to end of command line Ctrl+w # Cut last word Ctrl+k # Cut to the end of the line Ctrl+y # Paste (\"yank\") content that was cut earlier (by Ctrl-w or Ctrl-k) When specifying file names: . (dot) - refers to the present working directory ~ (tilde) or ~/ - refers to user's home directory","title":"Handy shortcuts"},{"location":"hpc-linux/#other-useful-unix-commands","text":"df # disk space free -g # memory info in Megabytes uname -a # shows tech info about machine bc # command-line calculator (to exit type 'quit') wget ftp://ftp.ncbi.nih.... # file download from web /sbin/ifconfig # give IP and other network info ln -s <original_filename> <new_filename> # creates symbolic link to file or directory du -sh # displays disk space usage of current directory du -sh * # displays disk space usage of individual files/directories du -s * | sort -nr # shows disk space used by different directories/files sorted by size","title":"Other Useful Unix Commands"},{"location":"hpc-linux/#unix-help","text":"help <command> # Show help for a Bash command man <something> # Show the manual page for a program (press the 'q' key to exit) man wc # Manual on program 'word count' wc wc --help # Short help on wc soap -h # For less standard programs Online help: Google is your friend. Universally available Linux commands, with detailed examples and explanations: https://www.linuxconfig.org/linux-commands","title":"Unix Help"},{"location":"hpc-linux/#finding-files-directories-and-applications","text":"find -name \"*pattern*\" # Searches for *pattern* in and below current directory find /usr/local -name \"*blast*\" # Finds file names *blast* in specfied directory find /usr/local -iname \"*blast*\" # Same as above, but case insensitive Additional useful arguments: -user , -group , -ctime find ~ -type f -mtime -2 # Finds all files you have modified in the last two days locate <pattern> # Finds files and dirs that are written into update file which <application_name> # Location of application whereis <application_name> # Searches for executables in set of directories yum list installed | grep <mypattern> # Find CentOS packages and refine search with grep pattern","title":"Finding files, directories and applications"},{"location":"hpc-linux/#finding-things-in-files","text":"grep <pattern> <file> # Provides lines in 'file' where pattern 'appears' # If pattern is shell function use single-quotes: '>' grep -H <pattern> # -H prints out file name in front of pattern grep 'pattern' <file> | wc # pipes lines with pattern into word count wc (see chapter 8) # wc arguments: -c: show only bytes, -w: show only words, # -l: show only lines; help on regular expressions: # $ man 7 regex or man perlre find /home/my_dir -name '*.txt' | xargs grep -c ^.* # Counts line numbers on many # files and records each count along with individual file # name; find and xargs are used to circumvent the Linux # wildcard limit to apply this function on thousands of files.","title":"Finding things in files"},{"location":"hpc-linux/#ownership-overview","text":"In Linux (and Unix systems in general), access to files and directories is controlled by a system of owners, groups, and permission bits. Changing these settings is necessary to control access by other users. The permission system also affects what files can be executed.","title":"Ownership Overview"},{"location":"hpc-linux/#ownership-levels","text":"user (u) - User ownership of a file/directory. This user has the special right to change the permission bits and group ownership. group (g) - Group ownership of a file/directory. Members of this group may be assigned greater access rights than non-members. other (o) - Everyone else that isn't the owning user or from the owning group.","title":"Ownership Levels"},{"location":"hpc-linux/#permission-bits","text":"The elemental permissions in Linux/Unix are read, write, and execute. Users and groups can have one many, or none of these rights. Their meanings are as follows: Letter Number File Directory Read r 4 View the contents View the listings Write w 2 Modify the contents Create a new file, or rename or delete existing files Execute x 1 Execute a program/script Traversal rights","title":"Permission Bits"},{"location":"hpc-linux/#checking-permissions","text":"Annotated output for ls -la : ---------- File type (d = directory, - = regular file, l = symlink) |--------- User permission triplet || ------ Group permission triplet || | --- Other permission triplet || | | || | | [user] [group] drwx-----x 61 aleong operations 4096 Feb 24 16:39 ./ drwxr-xr-x 688 root root 262144 Feb 24 11:05 ../ drwx------ 2 aleong operations 4096 Feb 2 22:45 .ssh/ drwxr-xr-x 5 aleong operations 4096 Dec 12 15:57 Downloads/ drwxr-xr-x 2 aleong operations 4096 Jan 9 16:29 bin/ -rw------- 1 aleong operations 7960 Feb 23 18:37 .bash_history -rw-r--r-- 1 aleong operations 306 Nov 3 15:08 .bashrc -rw-r--r-- 1 aleong operations 677 Apr 8 2013 .profile -rw-r--r-- 1 aleong operations 128 Nov 30 12:38 .tmux.conf -rw-r--r-- 1 aleong operations 12126 Nov 2 13:14 .vimrc lrwxrwxrwx 1 aleong operations 23 Sep 12 10:49 bigdata -> /bigdata/operations/aleong/ -rw-r--r-- 1 aleong operations 5657 Sep 19 11:31 bookmarks.html lrwxrwxrwx 1 aleong operations 23 Sep 12 10:49 shared -> /bigdata/operations/shared/ Assign write and execute permissions to user and group chmod ug+rx my_file To remove all permissions from all three user groups chmod ugo-rwx my_file # '+' causes the permissions selected to be added # '-' causes them to be removed # '=' causes them to be the only permissions that the file has. chmod +rx public_html/ or $ chmod 755 public_html/ # Example for number system:","title":"Checking Permissions"},{"location":"hpc-linux/#change-ownership","text":"chown <user> <file or dir> # changes user ownership chgrp <group> <file or dir> # changes group ownership chown <user>:<group> <file or dir> # changes user & group ownership","title":"Change ownership"},{"location":"hpc-linux/#process-management","text":"top # view top consumers of memory and CPU (press 1 to see per-CPU statistics) who # Shows who is logged into system w # Shows which users are logged into system and what they are doing ps # Shows processes running by user ps -e # Shows all processes on system; try also '-a' and '-x' arguments ps aux | grep <user_name> # Shows all processes of one user ps ax --tree # Shows the child-parent hierarchy of all processes ps -o %t -p <pid> # Shows how long a particular process was running. # (E.g. 6-04:30:50 means 6 days 4 hours ...) Ctrl z <enter> # Suspend (put to sleep) a process fg # Resume (wake up) a suspended process and brings it into foreground bg # Resume (wake up) a suspended process but keeps it running # in the background. Ctrl c # Kills the process that is currently running in the foreground kill <process-ID> # Kills a specific process kill -9 <process-ID> # NOTICE: \"kill -9\" is a very violent approach. # It does not give the process any time to perform cleanup procedures. kill -l # List all of the signals that can be sent to a proccess kill -s SIGSTOP <process-ID> # Suspend (put to sleep) a specific process kill -s SIGCONT <process-ID> # Resume (wake up) a specific process nice -n <nice_value> <cmd> # Run a program with lower priority. Be nice to other headnode users. # Higher \"nice\" values mean lower priority. Range 0-20 renice -n <priority_value> <process-ID> # Changes the priority of an existing process.","title":"Process Management"},{"location":"hpc-linux/#more-on-terminating-processes","text":"DigitalOcean - How To Use ps, kill, and nice to Manage Processes in Linux","title":"More on Terminating Processes"},{"location":"hpc-linux/#vim-manual","text":"","title":"Vim Manual"},{"location":"hpc-linux/#basics_1","text":"vim <my_file_name> # open/create file with vim Once you are in Vim the most important commands are i , : and ESC . The i key brings you into the insert mode for typing. ESC brings you out of there. And the : key starts the command mode at the bottom of the screen. In the following text, all commands starting with : need to be typed in the command mode. All other commands are typed in the normal mode after hitting the ESC key. Modifier Keys to Control Vim i # INSERT MODE ESC # NORMAL (NON-EDITING) MODE : # commands start with ':' :w # save command; if you are in editing mode you have to hit ESC first!! :q # quit file, don't save :q! # exits WITHOUT saving any changes you have made :wq # save and quit R # replace MODE r # replace only one character under cursor q: # history of commands (from NORMAL MODE!), to reexecute one of them, select and hit enter! :w new_filename # saves into new file :#,#w new_filename # saves specific lines (#,#) to new file :# # go to specified line number","title":"Basics"},{"location":"hpc-linux/#vim-help","text":"Online Help Find help on the web. Google will find answers to most questions on vi and vim (try searching for both terms). Purdue University Vi Tutorial Animated Vim Tutorial: https://linuxconfig.org/vim-tutorial Useful list of vim commands: Vim Commands Cheat Sheet VimCard Help from Command Line vimtutor # open vim tutorial from shell Help in Vim :help # opens help within vim, hit :q to get back to your file :help <topic> # opens help on specified topic :help_topic| CTRL-] # when you are in help this command opens help topic specified between |...|, # CTRL-t brings you back to last topic :help <topic> CTRL-D # gives list of help topics that contain key word : <up-down keys> # like in shell you get recent commands!!!! Moving Around in Files $ # moves cursor to end of line A # same as $, but switches to insert mode 0 (zero) # moves cursor to beginning of line CTRL-g # shows at status line filename and the line you are on SHIFT-G # brings you to bottom of file, type line number (isn't displayed) then SHIFT-G # brings you to specified line# Line Wrapping and Line Numbers :set nowrap # no word wrapping, :set wrap # back to wrapping :set number # shows line numbers, :set nonumber # back to no-number mode Working with Many Files & Splitting Windows vim -o *.txt # opens many files at once and displays them with horizontal # split, '-O' does vertical split vim *.txt # opens many files at once; ':n' switches between files :wall or :qall # write or quit all open files :args *.txt # places all the relevant files in the argument list :all # splits all files in the argument list (buffer) horizontally CTRL-w # switch between windows :split # shows same file in two windows :split <file-to-open> # opens second file in new window :vsplit # splits windows vertically, very useful for tables, \":set scrollbind\" let's you scroll all open windows simultaneously :close # closes current window :only # closes all windows except current one Spell Checking & Dictionary :set spell # turns on spell checking :set nospell # turns spell checking off :! dict <word> # meaning of word :! wn 'word' -over # synonyms of word Enabling Syntax Highlighting :set filetype=perl # Turns on syntax coloring for a chosen programming language. :set syntax on # Turns syntax highlighting on :set syntax off # Turns syntax highlighting off Undo and Redo u # undo last command U # undo all changes on current line CTRL-R # redo one change which was undone Deleting Things x # deletes what is under cursor dw # deletes from curser to end of word including the space de # deletes from curser to end of word NOT including the space cw # deletes rest of word and lets you then insert, hit ESC to continue with NORMAL mode c$ # deletes rest of line and lets you then insert, hit ESC to continue with with NORMAL mode d$ # deletes from cursor to the end of the line dd # deletes entire line 2dd # deletes next two lines, continues: 3dd, 4dd and so on. Copy & Paste yy # copies line, for copying several lines do 2yy, 3yy and so on p # pastes clipboard behind cursor Search in Files /my_pattern # searches for my_pattern downwards, type n for next match ?my_pattern # seraches for my_pattern upwards, type n for next match :set ic # switches to ignore case search (case insensitive) :set hls # switches to highlight search (highlights search hits) Replacements with Regular Expression Support Great intro: A Tao of Regular Expressions :s/old_pat/new_pat/ # replaces first occurrence in a line :s/old_pat/new_pat/g # replaces all occurrence in a line :s/old_pat/new_pat/gc # add 'c' to ask for confirmation :#,#s/old_pat/new_pat/g # replaces all occurrence between line numbers: #,# :%s/old_pat/new_pat/g # replaces all occurrence in file :%s/\\(pattern1\\)\\(pattern2\\)/\\1test\\2/g # regular expression to insert, you need here '\\' in front of parentheses (<# Perl) :%s/\\(pattern.*\\)/\\1 my_tag/g # appends something to line containing pattern (<# .+ from Perl is .* in VIM) :%s/\\(pattern\\)\\(.*\\)/\\1/g # removes everything in lines after pattern :%s/\\(At\\dg\\d\\d\\d\\d\\d\\.\\d\\)\\(.*\\)/\\1\\t\\2/g # inserts tabs between At1g12345.1 and Description :%s/\\n/new_pattern/g # replaces return signs :%s/pattern/\\r/g # replace pattern with return signs!! :%s/\\(\\n\\)/\\1\\1/g # insert additional return signs :%s/\\(^At\\dg\\d\\d\\d\\d\\d.\\d\\t.\\{-}\\t.\\{-}\\t.\\{-}\\t.\\{-}\\t\\).\\{-}\\t/\\1/g # replaces content between 5th and 6th tab (5th column), '{-}' turns off 'greedy' behavior :#,#s/\\( \\{-} \\|\\.\\|\\n\\)/\\1/g # performs simple word count in specified range of text :%s/\\(E\\{6,\\}\\)/<font color=\"green\">\\1<\\/font>/g # highlight pattern in html colors, here highlighting of >= 6 occurences of Es :%s/\\([A-Z]\\)/\\l\\1/g # change uppercase to lowercase, '%s/\\([A-Z]\\)/\\u\\1/g' does the opposite :g/my_pattern/ s/\\([A-Z]\\)/\\l\\1/g | copy $ # uses 'global' command to apply replace function only on those lines that match a certain pattern. The 'copy $' command after the pipe '|' prints all matching lines at the end of the file. :args *.txt | all | argdo %s/\\old_pat/new_pat/ge | update # command 'args' places all relevant files in the argument list (buffer); 'all' displays each file in separate split window; command 'argdo' applies replacement to all files in argument list (buffer); flag 'e' is necessary to avoid stop at error messages for files with no matches; command 'update' saves all changes to files that were updated. Useful Utilities in Vim Matching Parentheses Place cursor on (, [ or { and type % # cursor moves to matching parentheses Printing and Inserting Files :ha # prints entire file :#,#ha # prints specified lines: #,# :r <filename> # inserts content of specified file after cursor Convert Text File to HTML Format :runtime! syntax/2html.vim # run this command with open file in Vim Shell Commands in Vim :!<SHELL_COMMAND> <ENTER> # executes any shell command, hit <enter> to return :sh # switches window to shell, 'exit' switches back to vim Using Vim as Table Editor v starts visual mode for selecting characters V starts visual mode for selecting lines` CTRL-V starts visual mode for selecting blocks (use CTRL-q in gVim under Windows). This allows column-wise selections and operations like inserting and deleting columns. To restrict substitute commands to a column, one can select it and switch to the command-line by typing : . After this the substitution syntax for a selected block looks like this: '<,'>s///. :set scrollbind starts simultaneous scrolling of 'vsplitted' files. To set to horizontal binding of files, use command :set scrollopt=hor (after first one). Run all these commands before the :split command. :AlignCtrl I= \\t then :%Align This allows to align tables by column separators (here '\\t') when the Align utility from Charles Campbell's is installed. To sort table rows by selected lines or block, perform the visual select and then hit F3 key. The rest is interactive. To enable this function, one has to include in the .vimrc file the Vim sort script from Gerald Lai. Modify Vim Settings The default settings in Vim are controlled by the .vimrc file in your home directory. see last chapter of vimtutor (start from shell) useful .vimrc sample when vim starts to respond very slowly then one may need to delete the .viminf* files in home directory","title":"Vim Help"},{"location":"hpc-linux/#text-viewing","text":"more <my_file> # views text, use space bar to browse, hit 'q' to exit less <my_file> # a more versatile text viewer than 'more', 'q' exits, 'G' moves to end of text, # 'g' to beginning, '/' find forward, '?' find backwards cat <my_file> # concatenates files and prints content to standard output","title":"Text Viewing"},{"location":"hpc-linux/#text-editors","text":"Vi and Vim Non-graphical (terminal-based) editor. Vi is guaranteed to be available on any system. Vim is the improved version of vi. Emacs Non-graphical or window-based editor. You still need to know keystroke commands to use it. Installed on all Linux distributions and on most other Unix systems. XEmacs More sophisticated version of emacs, but usually not installed by default. All common commands are available from menus. Very powerful editor, with built-in syntax checking, Web-browsing, news-reading, manual-page browsing, etc. Pico Simple terminal-based editor available on most versions of Unix. Uses keystroke commands, but they are listed in logical fashion at bottom of screen. Nano A simple terminal-based editor which is default on modern Debian systems.","title":"Text Editors"},{"location":"hpc-linux/#the-unix-shell","text":"When you log into UNIX/LINUX system, then is starts a program called the Shell. It provides you with a working environment and interface to the operating system. Usually there are several different shell programs installed. The shell program bash is one of the most common ones. finger <user_name> # shows which shell you are using chsh -l # gives list of shell programs available on your system (does not work on all UNIX variants) <shell_name> # switches to different shell","title":"The Unix Shell"},{"location":"hpc-linux/#stdin-stdout-stderr-redirections-and-wildcards","text":"See LINUX HOWTOs By default, UNIX commands read from standard input (STDIN) and send their output to standard out (STDOUT). You can redirect them by using the following commands: <beginning-of-filename>* # * is wildcard to specify many files ls > file # prints ls output into specified file command < my_file # uses file after '<' as STDIN command >> my_file # appends output of one command to file command | tee my_file # writes STDOUT to file and prints it to screen command > my_file; cat my_file # writes STDOUT to file and prints it to screen command > /dev/null # turns off progress info of applications by redirecting # their output to /dev/null grep my_pattern my_file | wc # Pipes (|) output of 'grep' into 'wc' grep my_pattern my_non_existing_file 2 > my_stderr # prints STDERR to file","title":"STDIN, STDOUT, STDERR, Redirections, and Wildcards"},{"location":"hpc-linux/#useful-shell-commands","text":"cat <file1> <file2> > <cat.out> # concatenate files in output file 'cat.out' paste <file1> <file2> > <paste.out> # merges lines of files and separates them by tabs (useful for tables) cmp <file1> <file2> # tells you whether two files are identical diff <fileA> <fileB> # finds differences between two files head -<number> <file> # prints first lines of a file tail -<number> <file> # prints last lines of a file split -l <number> <file> # splits lines of file into many smaller ones csplit -f out fasta_batch \"%^>%\" \"/^>/\" \"{*}\" # splits fasta batch file into many files # at '>' sort <file> # sorts single file, many files and can merge (-m) # them, -b ignores leading white space, ... sort -k 2,2 -k 3,3n input_file > output_file # sorts in table column 2 alphabetically and # column 3 numerically, '-k' for column, '-n' for # numeric sort input_file | uniq > output_file # uniq command removes duplicates and creates file/table # with unique lines/fields join -1 1 -2 1 <table1> <table2> # joins two tables based on specified column numbers # (-1 file1, 1: col1; -2: file2, col2). It assumes # that join fields are sorted. If that is not the case, # use the next command: sort table1 > table1a; sort table2 > table2a; join -a 1 -t \"$(echo -e '\\t')\" table1a table2a > table3 # '-a <table>' prints all lines of specified table! # Default prints only all lines the two tables have in # common. '-t \"$(echo -e '\\t')\" ->' forces join to # use tabs as field separator in its output. Default is # space(s)!!! cat my_table | cut -d , -f1-3 # cut command prints only specified sections of a table, # -d specifies here comma as column separator (tab is # default), -f specifies column numbers. grep # see chapter 4 egrep # see chapter 4","title":"Useful shell commands"},{"location":"hpc-linux/#screen","text":"Screen references Screen Turorial Screen Cheat Sheet","title":"Screen"},{"location":"hpc-linux/#starting-a-new-screen-session","text":"screen # Start a new session screen -S <some-name> # Start a new session and gives it a name Commands to Control Screen Ctrl-a d # Detach from the screen session Ctrl-a c # Create a new window inside the screen session Ctrl-a Space # Switch to the next window Ctrl-a a # Switch to the window that you were previously on Ctrl-a \" # List all open windows. Double-quotes \" are typed with the Shift key Ctrl-d or type exit # Exit out of the current window. Exiting form the last window will end the screen session Ctrl-a [ # Enters the scrolling mode. Use Page Up and Page Down keys to scroll through the window. Hit the Enter key twice to return to normal mode.","title":"Starting a New Screen Session"},{"location":"hpc-linux/#attaching-to-screen-sessions","text":"From any computer, you can attach to a screen session after SSH-ing into a server. screen -r # Attaches to an existing session, if there is only one screen -r # Lists available sessions and their names, if there are more then one session running screen -r <some-name> # Attaches to a specific session screen -r <first-few-letters-of-name> # Type just the first few letters of the name # and you will be attached to the session you need","title":"Attaching to Screen Sessions"},{"location":"hpc-linux/#destroying-screen-sessions","text":"Terminate all programs that are running in the screen session. The standard way to do that is: Ctrl-c Exit out of your shell: exit Repeat steps 1 and 2 until you see the message: [screen is terminating] There may be programs running in different windows of the same screen session. That's why you may need to terminate programs and exit shells multiple time.","title":"Destroying Screen Sessions"},{"location":"hpc-linux/#tabs-and-a-reasonably-large-history-buffer","text":"For a better experience with screen, run cp ~/.screenrc ~/.screenrc.backup 2> /dev/null echo 'startup_message off defscrollback 10240 caption always \"%{=b dy}{ %{= dm}%H %{=b dy}}%={ %?%{= dc}%-Lw%?%{+b dy}(%{-b r}%n:%t%{+b dy})%?(%u)%?%{-dc}%?%{= dc}%+Lw%? %{=b dy}}\" ' > ~/.screenrc","title":"Tabs and a Reasonably Large History Buffer"},{"location":"hpc-linux/#simple-one-liner-shell-scripts","text":"Web page for script download . Renames many files .old to .new. To test things first, replace 'do mv' with 'do echo mv': for i in *.input; do mv $i ${i/\\.old/\\.new}; done for i in *\\ *; do mv \"$i\" \"${i// /_}\"; done # Replaces spaces in files by underscores Run an application in loops on many input files: for i in *.input; do ./application $i; done Run fastacmd from BLAST program in loops on many .input files and create corresponding .out files: for i in *.input; do fastacmd -d /data/../database_name -i $i > $i.out; done Run SAM's target99 on many input files: for i in *.pep; do target99 -db /usr/../database_name -seed $i -out $i; done Search in many files for a pattern and print occurrences together with file names. for j in 0 1 2 3 4 5 6 7 8 9; do grep -iH <my_pattern> *$j.seq; done Example of how to run an interactive application (tmpred) that asks for file name input/output: for i in *.pep; do echo -e \"$i\\n\\n17\\n33\\n\\n\\n\" | ./tmpred $i > $i.out; done Run BLAST2 for all .fasa1/ .fasta2 file pairs in the order specified by file names and write results into one file: for i in *.fasta1; do blast2 -p blastp -i $i -j ${i/_*fasta1/_*fasta2} >> my_out_file; done This example uses two variables in a for loop. The content of the second variable gets specified in each loop by a replace function. Runs BLAST2 in all-against-all mode and writes results into one file ('-F F' turns low-complexity filter off): for i in *.fasta; do for j in *.fasta; do blast2 -p blastp -F F -i $i -j $j >> my_out_file; done; done;","title":"Simple One-Liner Shell Scripts"},{"location":"hpc-linux/#simple-one-liner-perl-scripts","text":"Small collection of useful one-liners: perl -p -i -w -e 's/pattern1/pattern2/g' my_input_file # Replaces a pattern in a file by a another pattern using regular expressions. # $1 or \\1: back-references to pattern placed in parentheses # -p: lets perl know to write program # -i.bak: creates backup file *.bak, only -i doesn't # -w: turns on warnings # -e: executable code follows Parse lines based on patterns: perl -ne 'print if (/my_pattern1/ ? ($c=1) : (--$c > 0)); print if (/my_pattern2/ ? ($d = 1) : (--$d > 0))' my_infile > my_outfile # Parses lines that contain pattern1 and pattern2. # The following lines after the pattern can be specified in '$c=1' and '$d=1'. # For logical OR use this syntax: '/(pattern1|pattern2)/'.","title":"Simple One-Liner Perl Scripts"},{"location":"hpc-linux/#ssh","text":"SSH is the main protocal used to communicate with or establish a terminal on remote systems.","title":"SSH"},{"location":"hpc-linux/#example","text":"ssh <username>@<remote-address> If you want to use a specific ssh key for this connection use the -i flag. ssh -i ~/.ssh/mykey <username>@<remote-address> If your username on the remote system is the same as your local username then you can omit the username from the command.","title":"Example"},{"location":"hpc-linux/#passwordless-login","text":"You can use ssh (RSA) keys to login with out the need for a password. (this is much quicker and very useful) Generate your ssh keys ssh-keygen Enter a blank password when asked in order to have a passwordless key By default the key will be stored as .ssh/id_rsa You can change this path to which ever you like Copy the public key to the remote system (there is now a tool for this) ssh-copy-id <username>@<remote-system> You can pass the -i flag to this command to copy a specific public key. This places your public key into the the file .ssh/authorized_keys on the remote system. You can do this manually if you like. Once this is complete you can login without a password.","title":"Passwordless login."},{"location":"hpc-linux/#ssh-remote-commands","text":"Often you may want to just run a command on the remote system. Just put the command or muplitple commands surounded by quotes after the ssh command ssh <username>@<remote-host> <command-you-want-to-run> ssh <username>@<remote-host> \"<command-you-want-to-run>; <command-you-want-to-run>; <command-you-want-to-run>\"","title":"SSH remote commands"},{"location":"hpc-linux/#remote-copy-wget-scp-ncftp","text":"","title":"Remote Copy: wget, scp, ncftp"},{"location":"hpc-linux/#wget","text":"Use wget to download a file from the web: wget ftp://ftp.ncbi.nih.... # file download from www; add option '-r' to download entire directories","title":"Wget"},{"location":"hpc-linux/#scp","text":"Use scp to copy files between machines (ie. laptop to server): scp source target # Use form 'userid@machine_name' if your local and remote user ids are different. # If they are the same you can use only 'machine_name'. Here are more scp examples: scp user@remote_host:file.name . # Copies file from server to local machine (type from local # machine prompt). The '.' copies to pwd, you can specify # here any directory, use wildcards to copy many files. scp file.name user@remote_host:~/dir/newfile.name # Copies file from local machine to server. scp -r user@remote_host:directory/ ~/dir # Copies entire directory from server to local machine.","title":"SCP"},{"location":"hpc-linux/#nice-ftp","text":"From the linux command line run ncftp and use it to get files: ncftp ncftp> open ftp.ncbi.nih.gov ncftp> cd /blast/executables ncftp> get blast.linux.tar.Z (skip extension: @) ncftp> bye","title":"Nice FTP"},{"location":"hpc-linux/#archiving-and-compressing","text":"","title":"Archiving and Compressing"},{"location":"hpc-linux/#creating-archives","text":"tar -cvf my_file.tar mydir/ # Builds tar archive of files or directories. For directories, execute command in parent directory. Don't use absolute path. tar -czvf my_file.tgz mydir/ # Builds tar archive with compression of files or directories. For # directories, execute command in parent directory. Don't use absolute path. zip -r mydir.zip mydir/ # Command to archive a directory (here mydir) with zip. tar -jcvf mydir.tar.bz2 mydir/ # Creates *.tar.bz2 archive","title":"Creating Archives"},{"location":"hpc-linux/#viewing-archives","text":"tar -tvf my_file.tar tar -tzvf my_file.tgz","title":"Viewing Archives"},{"location":"hpc-linux/#extracting-archives","text":"tar -xvf my_file.tar tar -xzvf my_file.tgz gunzip my_file.tar.gz # or unzip my_file.zip, uncompress my_file.Z, # or bunzip2 for file.tar.bz2 find -name '*.zip' | xargs -n 1 unzip # this command usually works for unzipping # many files that were compressed under Windows tar -jxvf mydir.tar.bz2 # Extracts *.tar.bz2 archive Try also: tar zxf blast.linux.tar.Z tar xvzf file.tgz Important options: f: use archive file p: preserve permissions v: list files processed x: exclude files listed in FILE z: filter the archive through gzip","title":"Extracting Archives"},{"location":"hpc-linux/#environment-variables","text":"xhost user@host # adds X permissions for user on server. echo $DISPLAY # shows current display settings export DISPLAY=<local_IP>:0 # change environment variable unsetenv DISPLAY # removes display variable env # prints all environment variables List of directories that the shell will search when you type a command: echo $PATH You can edit your default DISPLAY setting for your account by adding it to file .bash_profile","title":"Environment Variables"},{"location":"hpc-metrics/","text":"","title":"Metrics"},{"location":"hpc-monitoring/","text":"","title":"Monitoring"},{"location":"hpc-provisioning/","text":"Provisioning We will be talking about provisioning in the computing sense and mostly related to just high performance computing. Although this can go pretty far as HPC spans most of computing. Definition: Bring some resource online for use in the HPC Cluster such as: Nodes Users Virtual Machines Storage Outline Nodes Bare Metal DNS PXE TFTP IPMI ILO BIOS BOOT Order Provisioning Systems ROCKS OpenHPC Cobbler Users LDAP Kerberos NIS Local Accounts Virtual Machines Cloud Amazon Web Services (AWS) Google Cloud Platform (GCP) MS Azure HyperVisor Stacks ZenServer Proxmox kvm/libvirt VmWare MS HyperV","title":"Provisioning"},{"location":"hpc-provisioning/#provisioning","text":"We will be talking about provisioning in the computing sense and mostly related to just high performance computing. Although this can go pretty far as HPC spans most of computing. Definition: Bring some resource online for use in the HPC Cluster such as: Nodes Users Virtual Machines Storage","title":"Provisioning"},{"location":"hpc-provisioning/#outline","text":"Nodes Bare Metal DNS PXE TFTP IPMI ILO BIOS BOOT Order Provisioning Systems ROCKS OpenHPC Cobbler Users LDAP Kerberos NIS Local Accounts Virtual Machines Cloud Amazon Web Services (AWS) Google Cloud Platform (GCP) MS Azure HyperVisor Stacks ZenServer Proxmox kvm/libvirt VmWare MS HyperV","title":"Outline"},{"location":"hpc-schedulers/","text":"","title":"Schedulers"},{"location":"hpc-software/","text":"HPC Software System Packages C / C++ / C BLAST Blast Example Python Conda This is one of the best package managers i have used. It has many uses in an HPC environment. Conda list environments conda env list Conda - create new environment with python 3.7 conda create -y -n python3.7 python=3.7 Conda - create new environment with python 3.7 and install jupyter. conda create -y -n jupyter python=3.7 jupyter Conda - Delete environment conda env remove -y -n python3.7 Conda - Enable conda environment source activate <name-of-environment> Conda - Disable conda environment source deactivate Jupyter Notebooks The Jupyter Notebook is an open-source web application that allows you to create and share documents that contain live code, equations, visualizations and narrative text. Uses include: data cleaning and transformation, numerical simulation, statistical modeling, data visualization, machine learning, and much more. This can be installed on your local laptop or workstation. These can also be used on many HPC Clusters which is exciting because there is often more software there and access to many more cpu and memory. Installing Jupyter Notebooks If Anaconda is installed then Jupyter is all ready installed. If just conda is installed than run the following to install Juypter Notebooks. conda create -y -n jupyter python=3.7 jupyter source activate jupyter DASK For the python ecosystem, consider using Dask which provides advanced parallelism for analytics. Why use Dask versus (or along with) other options? Dask integrates with Numpy, Pandas, and Scikit-Learn, and it also: scales up to clusters with multiple nodes deployable on job queuing systems like PBS, Slurm, MOAB, SGE, and LSF also scales down to parallel usage of a single-node such as a server or laptop modern laptops often have a multi-core CPU, 16-32GB of RAM, and flash-based hard drives that can stream through data several times faster than HDDs or SSDs of even a year or two ago. supports a map-shuffle-reduce pattern popularized by Hadoop and is a smaller, lightweight alternative to Spark. works with MPI via mpi4py library and compatible with infiniband or other high speed networks. See example Dask Jobqueue for PBS cluster from dask_jobqueue import PBSCluster cluster = PBSCluster() cluster.scale(10) # Ask for ten workers from dask.distributed import Client client = Client(cluster) # Connect this local process to remote workers # wait for jobs to arrive, depending on the queue, this may take some time import dask.array as da x = ... # Dask commands now use these distributed resources Dask on HPC Presentation Gemma Gemma Site You can install this in your home directory. The latest release comes as binary so no need to compile or anything. Just download unpack and move the binary anywhere you want. wget https://github.com/genetics-statistics/GEMMA/releases/download/0.98.1/gemma-0.98.1-linux-static.gz gzip -d gemma-0.98.1-linux-static.gz chmod 755 gemma-0.98.1-linux-static ./gemma-0.98.1-linux-static cp ./gemma-0.98.1-linux-static <someplace> (if you want to) RSD RSD site Create a conda environment with your own version of python then load the prerequisite packagea and run the installer. Commands: conda create -n rsd python=2.7.14 source activate rsd module load ncbi-blast module load paml module load kalign git clone https://github.com/todddeluca/reciprocal_smallest_distance cd reciprocal_smallest_distance python setup.py install rsd_search -h Then on subsequent logins or shells run the following to load up your RSD install. source activate rsd module load ncbi-blast module load paml module load kalign rsd_search -h Matplotlib This is a plotting package for python. Install can be done through conda. conda create -n matplolib python=2.7.14 matplotlib source activate matplotlib When the system runs the sbatch job it spawns a new session and this session is not connected to your login session with the -XY. This sbatch job doesn't have a $DISPLAY environment. You can make some minor adjustments to your python code to use the Agg backend and this will allow you to not use a $DISPLAY and still save plots. Example: import matplotlib as mpl mpl.use('Agg') import matplotlib.pyplot as plt fig = plt.figure() ax = fig.add_subplot(111) ax.plot(range(10)) fig.savefig('temp.png') Mothur Mothur website The latest release comes as binary so no need to compile or anything. Just download and unpack the binary. Example: wget https://github.com/mothur/mothur/releases/download/v1.41.3/Mothur.linux_64.zip unzip Mothur.linux_64.zip cd mothur/ ./mothur -h","title":"Software"},{"location":"hpc-software/#hpc-software","text":"","title":"HPC Software"},{"location":"hpc-software/#system-packages","text":"","title":"System Packages"},{"location":"hpc-software/#c-c-c","text":"","title":"C / C++ / C"},{"location":"hpc-software/#blast","text":"","title":"BLAST"},{"location":"hpc-software/#blast-example","text":"","title":"Blast Example"},{"location":"hpc-software/#python","text":"","title":"Python"},{"location":"hpc-software/#conda","text":"This is one of the best package managers i have used. It has many uses in an HPC environment.","title":"Conda"},{"location":"hpc-software/#conda-list-environments","text":"conda env list","title":"Conda list environments"},{"location":"hpc-software/#conda-create-new-environment-with-python-37","text":"conda create -y -n python3.7 python=3.7","title":"Conda - create new environment with python 3.7"},{"location":"hpc-software/#conda-create-new-environment-with-python-37-and-install-jupyter","text":"conda create -y -n jupyter python=3.7 jupyter","title":"Conda - create new environment with python 3.7 and install jupyter."},{"location":"hpc-software/#conda-delete-environment","text":"conda env remove -y -n python3.7","title":"Conda - Delete environment"},{"location":"hpc-software/#conda-enable-conda-environment","text":"source activate <name-of-environment>","title":"Conda - Enable conda environment"},{"location":"hpc-software/#conda-disable-conda-environment","text":"source deactivate","title":"Conda - Disable conda environment"},{"location":"hpc-software/#jupyter-notebooks","text":"The Jupyter Notebook is an open-source web application that allows you to create and share documents that contain live code, equations, visualizations and narrative text. Uses include: data cleaning and transformation, numerical simulation, statistical modeling, data visualization, machine learning, and much more. This can be installed on your local laptop or workstation. These can also be used on many HPC Clusters which is exciting because there is often more software there and access to many more cpu and memory.","title":"Jupyter Notebooks"},{"location":"hpc-software/#installing-jupyter-notebooks","text":"If Anaconda is installed then Jupyter is all ready installed. If just conda is installed than run the following to install Juypter Notebooks. conda create -y -n jupyter python=3.7 jupyter source activate jupyter","title":"Installing Jupyter Notebooks"},{"location":"hpc-software/#dask","text":"For the python ecosystem, consider using Dask which provides advanced parallelism for analytics. Why use Dask versus (or along with) other options? Dask integrates with Numpy, Pandas, and Scikit-Learn, and it also: scales up to clusters with multiple nodes deployable on job queuing systems like PBS, Slurm, MOAB, SGE, and LSF also scales down to parallel usage of a single-node such as a server or laptop modern laptops often have a multi-core CPU, 16-32GB of RAM, and flash-based hard drives that can stream through data several times faster than HDDs or SSDs of even a year or two ago. supports a map-shuffle-reduce pattern popularized by Hadoop and is a smaller, lightweight alternative to Spark. works with MPI via mpi4py library and compatible with infiniband or other high speed networks. See example Dask Jobqueue for PBS cluster from dask_jobqueue import PBSCluster cluster = PBSCluster() cluster.scale(10) # Ask for ten workers from dask.distributed import Client client = Client(cluster) # Connect this local process to remote workers # wait for jobs to arrive, depending on the queue, this may take some time import dask.array as da x = ... # Dask commands now use these distributed resources","title":"DASK"},{"location":"hpc-software/#dask-on-hpc-presentation","text":"","title":"Dask on HPC Presentation"},{"location":"hpc-software/#gemma","text":"Gemma Site You can install this in your home directory. The latest release comes as binary so no need to compile or anything. Just download unpack and move the binary anywhere you want. wget https://github.com/genetics-statistics/GEMMA/releases/download/0.98.1/gemma-0.98.1-linux-static.gz gzip -d gemma-0.98.1-linux-static.gz chmod 755 gemma-0.98.1-linux-static ./gemma-0.98.1-linux-static cp ./gemma-0.98.1-linux-static <someplace> (if you want to)","title":"Gemma"},{"location":"hpc-software/#rsd","text":"RSD site Create a conda environment with your own version of python then load the prerequisite packagea and run the installer. Commands: conda create -n rsd python=2.7.14 source activate rsd module load ncbi-blast module load paml module load kalign git clone https://github.com/todddeluca/reciprocal_smallest_distance cd reciprocal_smallest_distance python setup.py install rsd_search -h Then on subsequent logins or shells run the following to load up your RSD install. source activate rsd module load ncbi-blast module load paml module load kalign rsd_search -h","title":"RSD"},{"location":"hpc-software/#matplotlib","text":"This is a plotting package for python. Install can be done through conda. conda create -n matplolib python=2.7.14 matplotlib source activate matplotlib When the system runs the sbatch job it spawns a new session and this session is not connected to your login session with the -XY. This sbatch job doesn't have a $DISPLAY environment. You can make some minor adjustments to your python code to use the Agg backend and this will allow you to not use a $DISPLAY and still save plots. Example: import matplotlib as mpl mpl.use('Agg') import matplotlib.pyplot as plt fig = plt.figure() ax = fig.add_subplot(111) ax.plot(range(10)) fig.savefig('temp.png')","title":"Matplotlib"},{"location":"hpc-software/#mothur","text":"Mothur website The latest release comes as binary so no need to compile or anything. Just download and unpack the binary. Example: wget https://github.com/mothur/mothur/releases/download/v1.41.3/Mothur.linux_64.zip unzip Mothur.linux_64.zip cd mothur/ ./mothur -h","title":"Mothur"},{"location":"ms01/","text":"Micro Story 01 Doctor Strange Watching doctor strange the urg to write came upon me again. I like the style of the things in the rooms and how this all looked. People are coming,, time to go.","title":"Micro Story 01"},{"location":"ms01/#micro-story-01","text":"","title":"Micro Story 01"},{"location":"ms01/#doctor-strange","text":"Watching doctor strange the urg to write came upon me again. I like the style of the things in the rooms and how this all looked. People are coming,, time to go.","title":"Doctor Strange"},{"location":"other-presentations/","text":"Note Worthy Presentations by Others - Great application slowness trouble shooting on TACC's stampead. Link","title":"Other Presentations"},{"location":"other-presentations/#note-worthy-presentations-by-others","text":"","title":"Note Worthy Presentations by Others"},{"location":"other-presentations/#-great-application-slowness-trouble-shooting-on-taccs-stampead","text":"Link","title":"- Great application slowness trouble shooting on TACC's stampead."},{"location":"presentations/","text":"Presentations - Introduction to Python - Linux and HPCC Cluster Introduction - Using HPCC Linux Cluster - HPC in the Cloud - Windows Apps to Linux Clusters","title":"My Presentations"},{"location":"presentations/#presentations","text":"","title":"Presentations"},{"location":"presentations/#-introduction-to-python","text":"","title":"- Introduction to Python"},{"location":"presentations/#-linux-and-hpcc-cluster-introduction","text":"","title":"- Linux and HPCC Cluster Introduction"},{"location":"presentations/#-using-hpcc-linux-cluster","text":"","title":"- Using HPCC Linux Cluster"},{"location":"presentations/#-hpc-in-the-cloud","text":"","title":"- HPC in the Cloud"},{"location":"presentations/#-windows-apps-to-linux-clusters","text":"","title":"- Windows Apps to Linux Clusters"},{"location":"project2/","text":"Project 2","title":"Project 2"},{"location":"project2/#project-2","text":"","title":"Project 2"},{"location":"slurm-submission-scripts/","text":"Slurm Slurm is a resource scheduler for HPC Clusters. Slurm submission scripts are how you ask for resources on the cluster and what to do with those resources once you get them. I have a collection of different examples I have used. Its stored on GitHub - Charles Forsyth . Select examples shown below. Spark Example This example very specific to the HPCC Cluster at UCR. It does the following: Creates a spark cluster on nodes allocated from slurm on the HPCC Cluster Spawns the spark master on the first node Spawns spark workers on the rest of the nodes Counts words in a text file of moby dick across all nodes. Other examples from the spark website spark_job.slurm #!/bin/bash -l #SBATCH -p short #SBATCH --nodes=3 #SBATCH --cpus-per-task=8 #SBATCH --ntasks-per-node=1 #SBATCH --time=0:20:00 #SBATCH --job-name=spark-example nodes=($( scontrol show hostnames $SLURM_NODELIST )) nnodes=${#nodes[@]} last=$(( $nnodes - 1 )) cd $SLURM_WORKING_DIR export SPARK_HOME=/rhome/forsythc/bigdata/bin/spark ssh ${nodes[0]}.ib.int.bioinfo.ucr.edu \"module load java/8u45; cd ${SPARK_HOME}; ./sbin/start-master.sh\" sparkmaster=\"spark://${nodes[0]}:7077\" SCRATCH=/rhome/forsythc/bigdata/scratch/ mkdir -p ${SCRATCH}/work rm -f ${SCRATCH}/work/nohup*.out for i in $( seq 0 $last ); do ssh ${nodes[$i]}.ib.int.bioinfo.ucr.edu \"cd ${SPARK_HOME}; module load java/8u45; nohup ./bin/spark-class org.apache.spark.deploy.worker.Worker ${sparkmaster} &> ${SCRATCH}/work/nohup-${nodes[$i]}.out\" & done rm -rf ${SCRATCH}/wordcounts cat > sparkscript.py <<EOF from pyspark import SparkContext sc = SparkContext(appName=\"wordCount\") file = sc.textFile(\"${SCRATCH}/moby-dick.txt\") counts = file.flatMap(lambda line: line.split(\" \")).map(lambda word: (word, 1)).reduceByKey(lambda a, b: a+b) counts.saveAsTextFile(\"${SCRATCH}/wordcounts\") EOF module load java/8u45 ${SPARK_HOME}/bin/spark-submit --master ${sparkmaster} sparkscript.py echo \"Tried to use host name ${nnodes[0]} maybe we should use ${nodes[0]}\" ssh ${nodes[0]}.ib.int.bioinfo.ucr.edu \"module load java/8u45; cd ${SPARK_HOME}; ./sbin/stop-master.sh\" for i in $( seq 0 $last ); do ssh ${nodes[$i]}.ib.int.bioinfo.ucr.edu \"killall java\" done wait","title":"Slurm"},{"location":"slurm-submission-scripts/#slurm","text":"Slurm is a resource scheduler for HPC Clusters. Slurm submission scripts are how you ask for resources on the cluster and what to do with those resources once you get them. I have a collection of different examples I have used. Its stored on GitHub - Charles Forsyth . Select examples shown below.","title":"Slurm"},{"location":"slurm-submission-scripts/#spark-example","text":"This example very specific to the HPCC Cluster at UCR. It does the following: Creates a spark cluster on nodes allocated from slurm on the HPCC Cluster Spawns the spark master on the first node Spawns spark workers on the rest of the nodes Counts words in a text file of moby dick across all nodes. Other examples from the spark website","title":"Spark Example"},{"location":"slurm-submission-scripts/#spark_jobslurm","text":"#!/bin/bash -l #SBATCH -p short #SBATCH --nodes=3 #SBATCH --cpus-per-task=8 #SBATCH --ntasks-per-node=1 #SBATCH --time=0:20:00 #SBATCH --job-name=spark-example nodes=($( scontrol show hostnames $SLURM_NODELIST )) nnodes=${#nodes[@]} last=$(( $nnodes - 1 )) cd $SLURM_WORKING_DIR export SPARK_HOME=/rhome/forsythc/bigdata/bin/spark ssh ${nodes[0]}.ib.int.bioinfo.ucr.edu \"module load java/8u45; cd ${SPARK_HOME}; ./sbin/start-master.sh\" sparkmaster=\"spark://${nodes[0]}:7077\" SCRATCH=/rhome/forsythc/bigdata/scratch/ mkdir -p ${SCRATCH}/work rm -f ${SCRATCH}/work/nohup*.out for i in $( seq 0 $last ); do ssh ${nodes[$i]}.ib.int.bioinfo.ucr.edu \"cd ${SPARK_HOME}; module load java/8u45; nohup ./bin/spark-class org.apache.spark.deploy.worker.Worker ${sparkmaster} &> ${SCRATCH}/work/nohup-${nodes[$i]}.out\" & done rm -rf ${SCRATCH}/wordcounts cat > sparkscript.py <<EOF from pyspark import SparkContext sc = SparkContext(appName=\"wordCount\") file = sc.textFile(\"${SCRATCH}/moby-dick.txt\") counts = file.flatMap(lambda line: line.split(\" \")).map(lambda word: (word, 1)).reduceByKey(lambda a, b: a+b) counts.saveAsTextFile(\"${SCRATCH}/wordcounts\") EOF module load java/8u45 ${SPARK_HOME}/bin/spark-submit --master ${sparkmaster} sparkscript.py echo \"Tried to use host name ${nnodes[0]} maybe we should use ${nodes[0]}\" ssh ${nodes[0]}.ib.int.bioinfo.ucr.edu \"module load java/8u45; cd ${SPARK_HOME}; ./sbin/stop-master.sh\" for i in $( seq 0 $last ); do ssh ${nodes[$i]}.ib.int.bioinfo.ucr.edu \"killall java\" done wait","title":"spark_job.slurm"}]}